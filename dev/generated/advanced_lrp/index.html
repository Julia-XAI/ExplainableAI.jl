<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced LRP · ExplainableAI.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ExplainableAI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ExplainableAI.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../example/">Getting started</a></li><li class="is-active"><a class="tocitem" href>Advanced LRP</a><ul class="internal"><li><a class="tocitem" href="#Custom-LRP-composites"><span>Custom LRP composites</span></a></li><li><a class="tocitem" href="#Custom-LRP-rules"><span>Custom LRP rules</span></a></li><li><a class="tocitem" href="#Custom-layers-and-activation-functions"><span>Custom layers and activation functions</span></a></li><li><a class="tocitem" href="#How-it-works-internally"><span>How it works internally</span></a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Advanced LRP</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced LRP</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adrhill/ExplainableAI.jl/blob/master/docs/literate/advanced_lrp.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Advanced-LRP-usage"><a class="docs-heading-anchor" href="#Advanced-LRP-usage">Advanced LRP usage</a><a id="Advanced-LRP-usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-LRP-usage" title="Permalink"></a></h1><p>One of the design goals of ExplainableAI.jl is to combine ease of use and extensibility for the purpose of research.</p><p>This example will show you how to implement custom LRP rules and register custom layers and activation functions. For this purpose, we will quickly load our model from the previous section:</p><pre><code class="language-julia hljs">using ExplainableAI
using Flux
using MLDatasets
using ImageCore
using BSON

model = BSON.load(&quot;../model.bson&quot;, @__MODULE__)[:model]

index = 10
x, _ = MNIST(Float32, :test)[10]
input = reshape(x, 28, 28, 1, :);</code></pre><h2 id="Custom-LRP-composites"><a class="docs-heading-anchor" href="#Custom-LRP-composites">Custom LRP composites</a><a id="Custom-LRP-composites-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-LRP-composites" title="Permalink"></a></h2><p>Instead of creating an LRP-analyzer from a single rule (e.g. <code>LRP(model, GammaRule())</code>), we can also assign rules to each layer individually. For this purpose, we create an array of rules that matches the length of the Flux chain:</p><pre><code class="language-julia hljs">rules = [
    ZBoxRule(0.0f0, 1.0f0),
    GammaRule(),
    GammaRule(),
    EpsilonRule(),
    EpsilonRule(),
    EpsilonRule(),
    ZeroRule(),
    ZeroRule(),
]

analyzer = LRP(model, rules)
heatmap(input, analyzer)</code></pre><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA9VJREFUeAHtwc1q1HcUx+HP7z/fOE4miS9oLCSRkYhCrYWCq7RVWnoHRXCnN+G29D5EcOFVuCwUiou6acTXQKPVoE18iUZNMvPr6pxshBI5xkTO82iwPiDFESmUSKFECiVSKJFCiRRKpFAihRIplEihRAolUiiRQokUSqRQIoUSKZRIoUQKJVIokUKJFEqkUCKFEimUSKFECiV2iMqG5v5d3K1buPFx3KlTmNWBMEOtysckUiiRQokUSmwDhYp7+wa3sIApS0u4fh8n4d69w83PY3aNj2OerY1glpdxkxMVU/hwIoUSKZRIocQWKv01XEuYN6sNpvPsGW4wwE1M4F6/xk1M4JaXcfPzuLk5THvmJ8yeMdzKm4LpdiofSqRQIoUSKZT4yMrzJdzevbj1NczKShvTOXAAN7QLUyn8n7L6FrN+7EtMU3DDt2/iOh3MSCm4yUlMLS02Q6RQIoUSKZQIUzHl0T+4gwcxv/3ewgwGLczJk7j+0G5MQ2UzZuc6mF4P127jmpERXKuF63Zx/T5OLTZDpFAihRIplPgIXoxNYfZoHfP9txXzdLFg9u+tbEZlw3q/YE4cW8PduYMbHsa8OngE0zS44foaM9AuTGFzRAolUiiRQokghYrZc/9P3L17mHLtGmb84kXcH7dxc3O4c+dws7OYMj2N2XX9Oq7TwR0+jKsVMzJ4ifl7cQxz6FAX06byoUQKJVIokUKJIAMaTDM2hpudxV25grt8Gdft4rpd3MgI7tIl3IULuOPHcU+e4J4+xfV6OAkzNYkrVCKIFEqkUCKFEkEKG+qRadwvv2LKiRO44WHc/Dyu18MdPYo7fRr38CFu3z7c4iKu3eZ9Bu0OplCJJlIokUKJFEpsofrzWT5UWX6Bu3oVd+QIbmoKNzODqTSYwsclUiiRQokUSmxjjxYKZuLlY9yhQ7jhYUz94Uc2FD4FkUKJFEqkUGKb+etmwdy6hTs7M4Y7fx63tISpFEzh0xAplEihRAoltoGXrwpGwp05g3vcn8As3MVNT49gRql8aiKFEimUSKHENtA0uJUV3PFjFVMpmNFRXLdT2U5ECiVSKJFCiU9kQMHcuIGbm8M1TcF88/UA0+0UtiuRQokUSqRQYktVzIMHBdPr4ZoGNzqKqxR2ApFCiRRKpFBiC5XFfzE9rWLmB5OY7756jumP7mWnESmUSKFECiW20uIi7sABzBd72DDYjWmo7DQihRIplEihxFbatw/X6WBWV3FDnTY7mUihRAolUiixlfbvx5WCafP5ECmUSKFECiW2UG0N8T6i8rkQKZRIoUQK9R8EDcYFzmNcXQAAAABJRU5ErkJg"><p>Since some Flux Chains contain other Flux Chains, ExplainableAI provides a utility function called <a href="../../api/#ExplainableAI.flatten_model"><code>flatten_model</code></a>.</p><div class="admonition is-warning"><header class="admonition-header">Flattening models</header><div class="admonition-body"><p>Not all models can be flattened, e.g. those using <code>Parallel</code> and <code>SkipConnection</code> layers.</p></div></div><h2 id="Custom-LRP-rules"><a class="docs-heading-anchor" href="#Custom-LRP-rules">Custom LRP rules</a><a id="Custom-LRP-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-LRP-rules" title="Permalink"></a></h2><p>Let&#39;s define a rule that modifies the weights and biases of our layer on the forward pass. The rule has to be of type <code>AbstractLRPRule</code>.</p><pre><code class="language-julia hljs">struct MyGammaRule &lt;: AbstractLRPRule end</code></pre><p>It is then possible to dispatch on the utility functions  <a href="../../api/#ExplainableAI.modify_params"><code>modify_params</code></a> and <a href="../../api/#ExplainableAI.modify_denominator"><code>modify_denominator</code></a> with the rule type <code>MyCustomLRPRule</code> to define custom rules without writing any boilerplate code. To extend internal functions, import them explicitly:</p><pre><code class="language-julia hljs">import ExplainableAI: modify_params

function modify_params(::MyGammaRule, W, b)
    ρW = W + 0.25 * relu.(W)
    ρb = b + 0.25 * relu.(b)
    return ρW, ρb
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">modify_params (generic function with 4 methods)</code></pre><p>We can directly use this rule to make an analyzer!</p><pre><code class="language-julia hljs">analyzer = LRP(model, MyGammaRule())
heatmap(input, analyzer)</code></pre><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA7xJREFUeAHtwctOlWcUx+Hf+/FHkGxACxF6AFtaDTFNihgdKKmHtAyMzhx7Ad6ZV+DACzBGozHGRGIIQQtuSXaRtlEE9vd29K49YQJZnMx6HtVbNcGPCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGVCK5EcCWCK3GIJWpMXWNevcLMz2OGhjDnz1O0G4MUFZm9JIIrEVyJ4EocAqnewiwuYp4+xczNYUZHMW/eYHp7MXNzFF1Xr2L6+ij+qsYpvvs2UyR2TwRXIrgSwZU4IGn9E2ZhAfPsGWZ4GDMzgxkZwdy8iVlcxDx/jrl/H3PnDsUP/W8p1jfHKXq6M7slgisRXIngSuyx9PFvTKuFWV7GDAxgLl3CDA9T5JPf0JHYTlpbw9y7h3n8GPPgAWZ2lqJ3fZ0i//wLHYmdEMGVCK5EcCXcZIr07i3m/XvM4CDmyhWKL3U3hYSpyOzExtlfKURHNT2NWVnBvH6NmZigSHRkdkYEVyK4EsGVcJI+f8K8e4dZWsL091N8/ukcRe+xzE5kOtp1olBXpqiay5jVVczUFKbZxExMUGQSuyWCKxFcieBK7IXVVczKCubRI4rjZ85g5uYwzSbmwgXMhw8U6dQpiqrZxPT2YqoKs7WFaTQw585R1I0BisTuieBKBFciuBJO8vE+ijQ1hWm1ME+eYGZnMYuLmMlJzPXrmIcPMbdvYy5exLx8ienvx5w9i5mcpKgbAxQJHyK4EsGVCK6Em0SRvx+jSHfvYiYmMK0WptXCjI9j+vowly9j5ucxrRZmaQlz7RpmepqiHjhBkfAngisRXIngSuyxTIWZ+Z3dSiMjmBcvMI0G5tYtzI0bFLkSRWJvieBKBFciuBKH2D//JYrB5WXM6dOY0VGK/MefdCQOggiuRHAlgitxyCw3E8XCAmZmbAwzOoo5cYIikygSB0MEVyK4EsGVOAS+bCaKjQ3MzG//0nGKou5rUGy1E0U3mYMmgisRXIngShwCEmZoiI5WC3PyJEWio7src5iI4EoEVyK4Egck05Ez26rHfqSo2hscBSK4EsGVCK7EvsoUVd2mqKqKIvd2UbRrTOrq5igQwZUIrkRwJfZR+vwJs7aGGRykOLa5SZEHBulIHAUiuBLBlQiuxH76+BHT04Pp7sb09NCROGpEcCWCKxFcif3UaLCdtnooKjJHmQiuRHAlgiuxnxoNvnYiuBLBlQiuxD7KqYvtVGS+FiK4EsGVCK7+B190wY0kWC+8AAAAAElFTkSuQmCC"><p>We just implemented our own version of the <span>$γ$</span>-rule in 7 lines of code! The outputs match perfectly:</p><pre><code class="language-julia hljs">analyzer = LRP(model, GammaRule())
heatmap(input, analyzer)</code></pre><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA7xJREFUeAHtwctOlWcUx+Hf+/FHkGxACxF6AFtaDTFNihgdKKmHtAyMzhx7Ad6ZV+DACzBGozHGRGIIQQtuSXaRtlEE9vd29K49YQJZnMx6HtVbNcGPCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGVCK5EcCWCK3GIJWpMXWNevcLMz2OGhjDnz1O0G4MUFZm9JIIrEVyJ4EocAqnewiwuYp4+xczNYUZHMW/eYHp7MXNzFF1Xr2L6+ij+qsYpvvs2UyR2TwRXIrgSwZU4IGn9E2ZhAfPsGWZ4GDMzgxkZwdy8iVlcxDx/jrl/H3PnDsUP/W8p1jfHKXq6M7slgisRXIngSuyx9PFvTKuFWV7GDAxgLl3CDA9T5JPf0JHYTlpbw9y7h3n8GPPgAWZ2lqJ3fZ0i//wLHYmdEMGVCK5EcCXcZIr07i3m/XvM4CDmyhWKL3U3hYSpyOzExtlfKURHNT2NWVnBvH6NmZigSHRkdkYEVyK4EsGVcJI+f8K8e4dZWsL091N8/ukcRe+xzE5kOtp1olBXpqiay5jVVczUFKbZxExMUGQSuyWCKxFcieBK7IXVVczKCubRI4rjZ85g5uYwzSbmwgXMhw8U6dQpiqrZxPT2YqoKs7WFaTQw585R1I0BisTuieBKBFciuBJO8vE+ijQ1hWm1ME+eYGZnMYuLmMlJzPXrmIcPMbdvYy5exLx8ienvx5w9i5mcpKgbAxQJHyK4EsGVCK6Em0SRvx+jSHfvYiYmMK0WptXCjI9j+vowly9j5ucxrRZmaQlz7RpmepqiHjhBkfAngisRXIngSuyxTIWZ+Z3dSiMjmBcvMI0G5tYtzI0bFLkSRWJvieBKBFciuBKH2D//JYrB5WXM6dOY0VGK/MefdCQOggiuRHAlgitxyCw3E8XCAmZmbAwzOoo5cYIikygSB0MEVyK4EsGVOAS+bCaKjQ3MzG//0nGKou5rUGy1E0U3mYMmgisRXIngShwCEmZoiI5WC3PyJEWio7src5iI4EoEVyK4Egck05Ez26rHfqSo2hscBSK4EsGVCK7EvsoUVd2mqKqKIvd2UbRrTOrq5igQwZUIrkRwJfZR+vwJs7aGGRykOLa5SZEHBulIHAUiuBLBlQiuxH76+BHT04Pp7sb09NCROGpEcCWCKxFcif3UaLCdtnooKjJHmQiuRHAlgiuxnxoNvnYiuBLBlQiuxD7KqYvtVGS+FiK4EsGVCK7+B190wY0kWC+8AAAAAElFTkSuQmCC"><p>If the layer doesn&#39;t use weights and biases <code>W</code> and <code>b</code>, ExplainableAI provides a lower-level variant of <a href="../../api/#ExplainableAI.modify_params"><code>modify_params</code></a> called <a href="../../api/#ExplainableAI.modify_layer"><code>modify_layer</code></a>. This function is expected to take a layer and return a new, modified layer.</p><div class="admonition is-warning"><header class="admonition-header">Using modify_layer</header><div class="admonition-body"><p>Use of the function <code>modify_layer</code> will overwrite functionality of <code>modify_params</code> for the implemented combination of rule and layer types. This is due to the fact that internally, <code>modify_params</code> is called by the default implementation of <code>modify_layer</code>.</p><p>Therefore it is recommended to only extend <code>modify_layer</code> for a specific rule and a specific layer type.</p></div></div><h2 id="Custom-layers-and-activation-functions"><a class="docs-heading-anchor" href="#Custom-layers-and-activation-functions">Custom layers and activation functions</a><a id="Custom-layers-and-activation-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-layers-and-activation-functions" title="Permalink"></a></h2><h3 id="Model-checks-for-humans"><a class="docs-heading-anchor" href="#Model-checks-for-humans">Model checks for humans</a><a id="Model-checks-for-humans-1"></a><a class="docs-heading-anchor-permalink" href="#Model-checks-for-humans" title="Permalink"></a></h3><p>Good model checks and presets should allow novice users to apply XAI methods in a &quot;plug &amp; play&quot; manner according to best practices.</p><p>Let&#39;s say we define a layer that doubles its input:</p><pre><code class="language-julia hljs">struct MyDoublingLayer end
(::MyDoublingLayer)(x) = 2 * x

mylayer = MyDoublingLayer()
mylayer([1, 2, 3])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Int64}:
 2
 4
 6</code></pre><p>Let&#39;s append this layer to our model:</p><pre><code class="language-julia hljs">model = Chain(model..., MyDoublingLayer())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
  Conv((5, 5), 1 =&gt; 6, relu),           # 156 parameters
  MaxPool((2, 2)),
  Conv((5, 5), 6 =&gt; 16, relu),          # 2_416 parameters
  MaxPool((2, 2)),
  Flux.flatten,
  Dense(256 =&gt; 120, relu),              # 30_840 parameters
  Dense(120 =&gt; 84, relu),               # 10_164 parameters
  Dense(84 =&gt; 10),                      # 850 parameters
  Main.MyDoublingLayer(),
)                   # Total: 10 arrays, 44_426 parameters, 174.867 KiB.</code></pre><p>Creating an LRP analyzer, e.g. <code>LRPZero(model)</code>, will throw an <code>ArgumentError</code> and print a summary of the model check in the REPL:</p><pre><code class="language-julia-repl hljs">┌───┬───────────────────────┬─────────────────┬────────────┬────────────────┐
│   │ Layer                 │ Layer supported │ Activation │ Act. supported │
├───┼───────────────────────┼─────────────────┼────────────┼────────────────┤
│ 1 │ flatten               │            true │     —      │           true │
│ 2 │ Dense(784, 100, relu) │            true │    relu    │           true │
│ 3 │ Dense(100, 10)        │            true │  identity  │           true │
│ 4 │ MyDoublingLayer()     │           false │     —      │           true │
└───┴───────────────────────┴─────────────────┴────────────┴────────────────┘
  Layers failed model check
  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡

  Found unknown layers MyDoublingLayer() that are not supported by ExplainableAI&#39;s LRP implementation yet.

  If you think the missing layer should be supported by default, please submit an issue (https://github.com/adrhill/ExplainableAI.jl/issues).

  These model checks can be skipped at your own risk by setting the LRP-analyzer keyword argument skip_checks=true.

  [...]</code></pre><p>LRP should only be used on deep rectifier networks and ExplainableAI doesn&#39;t recognize <code>MyDoublingLayer</code> as a compatible layer. By default, it will therefore return an error and a model check summary instead of returning an incorrect explanation.</p><p>However, if we know <code>MyDoublingLayer</code> is compatible with deep rectifier networks, we can register it to tell ExplainableAI that it is ok to use. This will be shown in the following section.</p><div class="admonition is-warning"><header class="admonition-header">Skipping model checks</header><div class="admonition-body"><p>All model checks can be skipped at the user&#39;s own risk by setting the LRP-analyzer keyword argument <code>skip_checks=true</code>.</p></div></div><h3 id="Registering-custom-layers"><a class="docs-heading-anchor" href="#Registering-custom-layers">Registering custom layers</a><a id="Registering-custom-layers-1"></a><a class="docs-heading-anchor-permalink" href="#Registering-custom-layers" title="Permalink"></a></h3><p>The error in the model check will stop after registering our custom layer type <code>MyDoublingLayer</code> as &quot;supported&quot; by ExplainableAI.</p><p>This is done using the function <a href="../../api/#ExplainableAI.LRP_CONFIG.supports_layer"><code>LRP_CONFIG.supports_layer</code></a>, which should be set to return <code>true</code> for the type <code>MyDoublingLayer</code>:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::MyDoublingLayer) = true</code></pre><p>Now we can create and run an analyzer without getting an error:</p><pre><code class="language-julia hljs">analyzer = LRPZero(model)
heatmap(input, analyzer)</code></pre><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA/FJREFUeAHtwcFqlGcUgOH3mznzz4wxGceYGDUoLTZgG1QIxVJRFKtrF11I7R0o3oN6A1l13boSCr2FUAUhVRw3QjWIYmpptY0YSFLNzHxdnZMuAmI4SSblPI90212CHyG4EoIrIbgSgishuBKCKyG4EoIrIbgSgishuBKCKyG4EoIrIbgSgishuBKCKyG4EoIrIbgSgishuBKCKyG4EoIrIbgSelgmsZrSzK+YBw8wzSbm5ElUu1JHlVNmPQnBlRBcCcGV0ANSZxmzvIxKc3OYhQXMwgKmVMKUSpi5OZRs3456/GcDVathRvdlVGLthOBKCK6E4ErYQKmzjHqbC9TcXIHaM8iKpSXM0BCm28VMTGBevcLcvYsZGUENfvIFamAAs7iUUH31zFoJwZUQXAnBlbDOMiuePC9Q8/OYly8xAycKVPXjMVQ5dTE7drKa1NeH6n5+DNXuJNTgs8eY2UVURQRz6FNUJvEhhOBKCK6E4Epwk1Fp/g3qj3+aqJs3MZ0O5uJFTK2GKZFZkXif2zMjqPEqplLBFPv3Y54/xxw4gAchuBKCKyG4EpxkSqgnfzdRtRrmzBnM3r2Y/aOZD5FZsdxOqBNfdjG/zWKKAvVwbg9qaGgMNSwdVCaxVkJwJQRXQnAlOCm136IOzj/E3HuMGp2exly6hPmphWm1MJcvY+7fR6Vjx1DVW7cwO3diRkYwQ0OojxqYR48wjUYZVUhmrYTgSgiuhOBKcJKlQKWiwLRamMlJzOQkplTC9Pdjjh7FXLuGuXoV8/o1ptPBVKuYwUHUtmYFdeRwBZXIeBCCKyG4EoIrYR3kQ5+h0vXrmPFxzPAw5vZtzO7dmKLAXLmCmZ7GnD+PefcO0+lgymVULpVRiYw3IbgSgishuBLWWS5XMN98y6q+Osf7pHu/YKamME+fYppNzPHjqLx9gI0iBFdCcCUEV0JPy5h6HXPqFKYoMGfPonJJ2AxCcCUEV0JwJfSYqZ8T6saNhPr+u4Oo33cdRu3ZnVGZFYnNIQRXQnAlBFdCD5h5klB37mBOn8b88OM21MIC5sKFhGo2MptNCK6E4EoIroQesLiIaTYx9TpmeBgzNoZpNjK9RAiuhOBKCK6ETdLJCfXsGWZ2FlOtYs6dwzT6M71KCK6E4EoIroRN8uIFZmIC025jRkcxjf7MViAEV0JwJQRXwgZKb16jDsgSamZxH+rrU3+hlvp2sdUIwZUQXAnBlbCRWi3MkSOovTtYkbahakVmqxGCKyG4EoIrYSP192P6+jBdTK7W2MqE4EoIroTgSthI4+OYbhdVqfAfia1MCK6E4EoIroQNlKt1VlMh838hBFdCcCUEV/8C77PGOhwUDWkAAAAASUVORK5C"><div class="admonition is-info"><header class="admonition-header">Registering functions</header><div class="admonition-body"><p>Flux&#39;s <code>Chains</code> can also contain functions, e.g. <code>flatten</code>. This kind of layer can be registered as</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::typeof(mylayer)) = true</code></pre></div></div><h3 id="Registering-activation-functions"><a class="docs-heading-anchor" href="#Registering-activation-functions">Registering activation functions</a><a id="Registering-activation-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Registering-activation-functions" title="Permalink"></a></h3><p>The mechanism for registering custom activation functions is analogous to that of custom layers:</p><pre><code class="language-julia hljs">myrelu(x) = max.(0, x)
model = Chain(Flux.flatten, Dense(784, 100, myrelu), Dense(100, 10))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
  Flux.flatten,
  Dense(784 =&gt; 100, myrelu),            # 78_500 parameters
  Dense(100 =&gt; 10),                     # 1_010 parameters
)                   # Total: 4 arrays, 79_510 parameters, 310.836 KiB.</code></pre><p>Once again, creating an LRP analyzer for this model will throw an <code>ArgumentError</code> and display the following model check summary:</p><pre><code class="language-julia-repl hljs">julia&gt; analyzer = LRPZero(model3)
┌───┬─────────────────────────┬─────────────────┬────────────┬────────────────┐
│   │ Layer                   │ Layer supported │ Activation │ Act. supported │
├───┼─────────────────────────┼─────────────────┼────────────┼────────────────┤
│ 1 │ flatten                 │            true │     —      │           true │
│ 2 │ Dense(784, 100, myrelu) │            true │   myrelu   │          false │
│ 3 │ Dense(100, 10)          │            true │  identity  │           true │
└───┴─────────────────────────┴─────────────────┴────────────┴────────────────┘
  Activations failed model check
  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡

  Found layers with unknown or unsupported activation functions myrelu. LRP assumes that the model is a &quot;deep rectifier network&quot; that only contains ReLU-like activation functions.

  If you think the missing activation function should be supported by default, please submit an issue (https://github.com/adrhill/ExplainableAI.jl/issues).

  These model checks can be skipped at your own risk by setting the LRP-analyzer keyword argument skip_checks=true.

  [...]</code></pre><p>Registation works by defining the function <a href="../../api/#ExplainableAI.LRP_CONFIG.supports_activation"><code>LRP_CONFIG.supports_activation</code></a> as <code>true</code>:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(::typeof(myrelu)) = true</code></pre><p>now the analyzer can be created without error:</p><pre><code class="language-julia hljs">analyzer = LRPZero(model)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LRP{Vector{ZeroRule}}(Chain(flatten, Dense(784 =&gt; 100, myrelu), Dense(100 =&gt; 10)), [ZeroRule(), ZeroRule(), ZeroRule()])</code></pre><h2 id="How-it-works-internally"><a class="docs-heading-anchor" href="#How-it-works-internally">How it works internally</a><a id="How-it-works-internally-1"></a><a class="docs-heading-anchor-permalink" href="#How-it-works-internally" title="Permalink"></a></h2><p>Internally, ExplainableAI dispatches to low level functions</p><pre><code class="language-julia hljs">function lrp!(rule, layer, Rₖ, aₖ, Rₖ₊₁)
    Rₖ .= ...
end</code></pre><p>These functions use the arguments <code>rule</code> and <code>layer</code> to dispatch <code>modify_params</code> and <code>modify_denominator</code> on the rule and layer type. They in-place modify a pre-allocated array of the input relevance <code>Rₖ</code> based on the input activation <code>aₖ</code> and output relevance <code>Rₖ₊₁</code>.</p><p>Calling <code>analyze</code> then applies a forward-pass of the model, keeping track of the activations <code>aₖ</code> for each layer <code>k</code>. The relevance <code>Rₖ₊₁</code> is then set to the output neuron activation and the rules are applied in a backward-pass over the model layers and previous activations.</p><h3 id="Generic-rule-implementation-using-automatic-differentiation"><a class="docs-heading-anchor" href="#Generic-rule-implementation-using-automatic-differentiation">Generic rule implementation using automatic differentiation</a><a id="Generic-rule-implementation-using-automatic-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Generic-rule-implementation-using-automatic-differentiation" title="Permalink"></a></h3><p>The generic LRP rule–of which the <span>$0$</span>-, <span>$\epsilon$</span>- and <span>$\gamma$</span>-rules are special cases–reads<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup><sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>:</p><p class="math-container">\[R_{j}=\sum_{k} \frac{a_{j} \cdot \rho\left(w_{j k}\right)}{\epsilon+\sum_{0, j} a_{j} \cdot \rho\left(w_{j k}\right)} R_{k}\]</p><p>where <span>$\rho$</span> is a function that modifies parameters – what we have so far called <code>modify_params</code>.</p><p>The computation of this propagation rule can be decomposed into four steps:</p><p class="math-container">\[\begin{array}{lr}
\forall_{k}: z_{k}=\epsilon+\sum_{0, j} a_{j} \cdot \rho\left(w_{j k}\right) &amp; \text { (forward pass) } \\
\forall_{k}: s_{k}=R_{k} / z_{k} &amp; \text { (element-wise division) } \\
\forall_{j}: c_{j}=\sum_{k} \rho\left(w_{j k}\right) \cdot s_{k} &amp; \text { (backward pass) } \\
\forall_{j}: R_{j}=a_{j} c_{j} &amp; \text { (element-wise product) }
\end{array}\]</p><p>For deep rectifier networks, the third step can also be written as the gradient computation</p><p class="math-container">\[c_{j}=\left[\nabla\left(\sum_{k} z_{k}(\boldsymbol{a}) \cdot s_{k}\right)\right]_{j}\]</p><p>and can be implemented via automatic differentiation (AD).</p><p>This equation is implemented in ExplainableAI as the default method for all layer types that don&#39;t have a specialized implementation. We will refer to it as the &quot;AD fallback&quot;.</p><h3 id="AD-fallback"><a class="docs-heading-anchor" href="#AD-fallback">AD fallback</a><a id="AD-fallback-1"></a><a class="docs-heading-anchor-permalink" href="#AD-fallback" title="Permalink"></a></h3><p>The default LRP fallback for unknown layers uses AD via <a href="https://github.com/FluxML/Zygote.jl">Zygote</a>. For <code>lrp!</code>, we end up with something that looks very similar to the previous four step computation:</p><pre><code class="language-julia hljs">function lrp!(rule, layer, Rₖ, aₖ, Rₖ₊₁)
    layerᵨ = modify_layer(rule, layer)
    c = gradient(aₖ) do a
            z = layerᵨ(a)
            s = Zygote.@ignore Rₖ₊₁ ./ modify_denominator(rule, z)
            z ⋅ s
	      end |&gt; only
    Rₖ .= aₖ .* c
end</code></pre><p>You can see how <code>modify_layer</code> and <code>modify_denominator</code> dispatch on the rule and layer type. This is how we implemented our own <code>MyGammaRule</code>. Unknown layers that are registered in the <code>LRP_CONFIG</code> use this exact function.</p><h3 id="Specialized-implementations"><a class="docs-heading-anchor" href="#Specialized-implementations">Specialized implementations</a><a id="Specialized-implementations-1"></a><a class="docs-heading-anchor-permalink" href="#Specialized-implementations" title="Permalink"></a></h3><p>We can also implement specialized versions of <code>lrp!</code> based on the type of <code>layer</code>, e.g. reshaping layers.</p><p>Reshaping layers don&#39;t affect attributions. We can therefore avoid the computational overhead of AD by writing a specialized implementation that simply reshapes back:</p><pre><code class="language-julia hljs">function lrp!(::AbstractLRPRule, ::ReshapingLayer, Rₖ, aₖ, Rₖ₊₁)
    Rₖ .= reshape(Rₖ₊₁, size(aₖ))
end</code></pre><p>Since the rule type didn&#39;t matter in this case, we didn&#39;t specify it.</p><p>We can even implement the generic rule as a specialized implementation for <code>Dense</code> layers:</p><pre><code class="language-julia hljs">function lrp!(rule::AbstractLRPRule, layer::Dense, Rₖ, aₖ, Rₖ₊₁)
    ρW, ρb = modify_params(rule, get_params(layer)...)
    ãₖ₊₁ = modify_denominator(rule, ρW * aₖ + ρb)
    @tullio Rₖ[j] = aₖ[j] * ρW[k, j] / ãₖ₊₁[k] * Rₖ₊₁[k] # Tullio ≈ fast einsum
end</code></pre><p>For maximum low-level control beyond <code>modify_layer</code>, <code>modify_params</code> and <code>modify_denominator</code>, you can also implement your own <code>lrp!</code> function and dispatch on individual rule types <code>MyRule</code> and layer types <code>MyLayer</code>:</p><pre><code class="language-julia hljs">function lrp!(rule::MyRule, layer::MyLayer, Rₖ, aₖ, Rₖ₊₁)
    Rₖ .= ...
end</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>G. Montavon et al., <a href="https://link.springer.com/chapter/10.1007/978-3-030-28954-6_10">Layer-Wise Relevance Propagation: An Overview</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>W. Samek et al., <a href="https://ieeexplore.ieee.org/document/9369420">Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../example/">« Getting started</a><a class="docs-footer-nextpage" href="../../api/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.18 on <span class="colophon-date" title="Wednesday 25 May 2022 18:02">Wednesday 25 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
