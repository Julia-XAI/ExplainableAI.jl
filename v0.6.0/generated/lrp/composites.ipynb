{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assigning LRP rules to layers\n",
    "In this example, we will show how to assign LRP rules to specific layers.\n",
    "For this purpose, we first define a small VGG-like convolutional neural network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ExplainableAI\n",
    "using Flux\n",
    "\n",
    "model = Chain(\n",
    "    Chain(\n",
    "        Conv((3, 3), 3 => 8, relu; pad=1),\n",
    "        Conv((3, 3), 8 => 8, relu; pad=1),\n",
    "        MaxPool((2, 2)),\n",
    "        Conv((3, 3), 8 => 16, relu; pad=1),\n",
    "        Conv((3, 3), 16 => 16, relu; pad=1),\n",
    "        MaxPool((2, 2)),\n",
    "    ),\n",
    "    Chain(\n",
    "        Flux.flatten,\n",
    "        Dense(1024 => 512, relu),\n",
    "        Dropout(0.5),\n",
    "        Dense(512 => 100, relu)\n",
    "    ),\n",
    ");"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manually assigning rules\n",
    "When creating an LRP-analyzer, we can assign individual rules to each layer.\n",
    "As we can see above, our model is a `Chain` of two Flux `Chain`s.\n",
    "Using `flatten_model`, we can flatten the model into a single `Chain`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((3, 3), 3 => 8, relu, pad=1),    \u001b[90m# 224 parameters\u001b[39m\n  Conv((3, 3), 8 => 8, relu, pad=1),    \u001b[90m# 584 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((3, 3), 8 => 16, relu, pad=1),   \u001b[90m# 1_168 parameters\u001b[39m\n  Conv((3, 3), 16 => 16, relu, pad=1),  \u001b[90m# 2_320 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Flux.flatten,\n  Dense(1024 => 512, relu),             \u001b[90m# 524_800 parameters\u001b[39m\n  Dropout(0.5),\n  Dense(512 => 100, relu),              \u001b[90m# 51_300 parameters\u001b[39m\n) \u001b[90m                  # Total: 12 arrays, \u001b[39m580_396 parameters, 2.216 MiB."
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "model_flat = flatten_model(model)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "This allows us to define an LRP analyzer using an array of rules\n",
    "matching the length of the Flux chain:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rules = [\n",
    "    FlatRule(),\n",
    "    ZPlusRule(),\n",
    "    ZeroRule(),\n",
    "    ZPlusRule(),\n",
    "    ZPlusRule(),\n",
    "    ZeroRule(),\n",
    "    PassRule(),\n",
    "    EpsilonRule(),\n",
    "    PassRule(),\n",
    "    EpsilonRule(),\n",
    "];"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `LRP` analyzer will show a summary of how layers and rules got matched:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  Conv((3, 3), 3 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mFlatRule()\u001b[39m,\n  Conv((3, 3), 8 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n  MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Conv((3, 3), 8 => 16, relu, pad=1) \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n  Conv((3, 3), 16 => 16, relu, pad=1)\u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n  MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Flux.flatten                       \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n  Dense(1024 => 512, relu)           \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  Dropout(0.5)                       \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n  Dense(512 => 100, relu)            \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "LRP(model_flat, rules)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, this approach only works for models that can be fully flattened.\n",
    "For unflattened models and models containing `Parallel` layers, we can compose rules using\n",
    "`ChainTuple`s and `ParallelTuple`s which match the model structure:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  ChainTuple(\n    Conv((3, 3), 3 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mFlatRule()\u001b[39m,\n    Conv((3, 3), 8 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 8 => 16, relu, pad=1) \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    Conv((3, 3), 16 => 16, relu, pad=1)\u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  ),\n  ChainTuple(\n    Flux.flatten            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(1024 => 512, relu)\u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n    Dropout(0.5)            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(512 => 100, relu) \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  ),\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "rules = ChainTuple(\n",
    "    ChainTuple(\n",
    "        FlatRule(),\n",
    "        ZPlusRule(),\n",
    "        ZeroRule(),\n",
    "        ZPlusRule(),\n",
    "        ZPlusRule(),\n",
    "        ZeroRule()\n",
    "    ),\n",
    "    ChainTuple(\n",
    "        PassRule(),\n",
    "        EpsilonRule(),\n",
    "        PassRule(),\n",
    "        EpsilonRule(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "analyzer = LRP(model, rules; flatten=false)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom composites\n",
    "Instead of manually defining a list of rules, we can also define a `Composite`.\n",
    "A composite constructs a list of LRP-rules by sequentially applying the\n",
    "composite primitives it contains.\n",
    "\n",
    "To obtain the same set of rules as in the previous example, we can define"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "composite = Composite(\n",
    "    GlobalTypeMap( # the following maps of layer types to LRP rules are applied globally\n",
    "        Conv                 => ZPlusRule(),   # apply ZPlusRule on all Conv layers\n",
    "        Dense                => EpsilonRule(), # apply EpsilonRule on all Dense layers\n",
    "        Dropout              => PassRule(),    # apply PassRule on all Dropout layers\n",
    "        MaxPool              => ZeroRule(),    # apply ZeroRule on all MaxPool layers\n",
    "        typeof(Flux.flatten) => PassRule(),    # apply PassRule on all flatten layers\n",
    "    ),\n",
    "    FirstLayerMap( # the following rule is applied to the first layer\n",
    "        FlatRule()\n",
    "    ),\n",
    ");"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now construct an LRP analyzer from `composite`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  ChainTuple(\n    Conv((3, 3), 3 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mFlatRule()\u001b[39m,\n    Conv((3, 3), 8 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 8 => 16, relu, pad=1) \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    Conv((3, 3), 16 => 16, relu, pad=1)\u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  ),\n  ChainTuple(\n    Flux.flatten            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(1024 => 512, relu)\u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n    Dropout(0.5)            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(512 => 100, relu) \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  ),\n)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "analyzer = LRP(model, composite; flatten=false)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, this analyzer contains the same rules as our previous one.\n",
    "To compute rules for a model without creating an analyzer, use `lrp_rules`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ChainTuple(\n  ChainTuple(\n    FlatRule(),\n    ZPlusRule(),\n    ZeroRule(),\n    ZPlusRule(),\n    ZPlusRule(),\n    ZeroRule(),\n  ),\n  ChainTuple(\n    PassRule(),\n    EpsilonRule{Float32}(1.0f-6),\n    PassRule(),\n    EpsilonRule{Float32}(1.0f-6),\n  ),\n)\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "lrp_rules(model, composite)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composite primitives\n",
    "The following Composite primitives](@ref api-composite-primitives) can used to construct a [`Composite`.\n",
    "\n",
    "To apply a single rule, use:\n",
    "* `LayerMap` to apply a rule to a layer at a given index\n",
    "* `GlobalMap` to apply a rule to all layers\n",
    "* `RangeMap` to apply a rule to a positional range of layers\n",
    "* `FirstLayerMap` to apply a rule to the first layer\n",
    "* `LastLayerMap` to apply a rule to the last layer\n",
    "\n",
    "To apply a set of rules to layers based on their type, use:\n",
    "* `GlobalTypeMap` to apply a dictionary that maps layer types to LRP-rules\n",
    "* `RangeTypeMap` for a `TypeMap` on generalized ranges\n",
    "* `FirstLayerTypeMap` for a `TypeMap` on the first layer of a model\n",
    "* `LastLayerTypeMap` for a `TypeMap` on the last layer\n",
    "* `FirstNTypeMap` for a `TypeMap` on the first `n` layers\n",
    "\n",
    "Primitives are called sequentially in the order the `Composite` was created with\n",
    "and overwrite rules specified by previous primitives."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assigning a rule to a specific layer\n",
    "To assign a rule to a specific layer, we can use `LayerMap`,\n",
    "which maps an LRP-rule to all layers in the model at the given index.\n",
    "\n",
    "To display indices, use the `show_layer_indices` helper function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ChainTuple(\n  ChainTuple(\n    (1, 1),\n    (1, 2),\n    (1, 3),\n    (1, 4),\n    (1, 5),\n    (1, 6),\n  ),\n  ChainTuple(\n    (2, 1),\n    (2, 2),\n    (2, 3),\n    (2, 4),\n  ),\n)\n"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "show_layer_indices(model)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's demonstrate `LayerMap` by assigning a specific rule to the last `Conv` layer\n",
    "at index `(1, 5)`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  ChainTuple(\n    Conv((3, 3), 3 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 8 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 8 => 16, relu, pad=1) \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 16 => 16, relu, pad=1)\u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  ),\n  ChainTuple(\n    Flux.flatten            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Dense(1024 => 512, relu)\u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Dropout(0.5)            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Dense(512 => 100, relu) \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  ),\n)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "composite = Composite(LayerMap((1, 5), EpsilonRule()))\n",
    "\n",
    "LRP(model, composite; flatten=false)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "This approach also works with `Parallel` layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composite presets\n",
    "ExplainableAI.jl provides a set of default composites.\n",
    "A list of all implemented default composites can be found\n",
    "in the API reference,\n",
    "e.g. the `EpsilonPlusFlat` composite:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Composite(\n  GlobalTypeMap(  \u001b[90m# all layers\u001b[39m\n\u001b[94m    Flux.Conv              \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.ConvTranspose     \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.CrossCor          \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.Dense             \u001b[39m => \u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n\u001b[94m    typeof(NNlib.dropout)  \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.AlphaDropout      \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.Dropout           \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.BatchNorm         \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(Flux.flatten)   \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(MLUtils.flatten)\u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(identity)       \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n ),\n  FirstLayerTypeMap(  \u001b[90m# first layer\u001b[39m\n\u001b[94m    Flux.Conv         \u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n\u001b[94m    Flux.ConvTranspose\u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n\u001b[94m    Flux.CrossCor     \u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n\u001b[94m    Flux.Dense        \u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n ),\n)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "composite = EpsilonPlusFlat()"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  ChainTuple(\n    Conv((3, 3), 3 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mFlatRule()\u001b[39m,\n    Conv((3, 3), 8 => 8, relu, pad=1)  \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n    Conv((3, 3), 8 => 16, relu, pad=1) \u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    Conv((3, 3), 16 => 16, relu, pad=1)\u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n    MaxPool((2, 2))                    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  ),\n  ChainTuple(\n    Flux.flatten            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(1024 => 512, relu)\u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n    Dropout(0.5)            \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n    Dense(512 => 100, relu) \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  ),\n)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "analyzer = LRP(model, composite; flatten=false)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
