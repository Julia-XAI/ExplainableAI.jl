var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ExplainabilityMethods","category":"page"},{"location":"#ExplainabilityMethods","page":"Home","title":"ExplainabilityMethods","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ExplainabilityMethods]","category":"page"},{"location":"#ExplainabilityMethods.EpsilonRule","page":"Home","title":"ExplainabilityMethods.EpsilonRule","text":"EpsilonRule(; ϵ=1f-6)\n\nConstructor for LRP-ϵ rule. Commonly used on middle layers.\n\nArguments:\n\nϵ: Optional stabilization parameter, defaults to 1f-6.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.GammaRule","page":"Home","title":"ExplainabilityMethods.GammaRule","text":"GammaRule(; γ=0.25)\n\nConstructor for LRP-γ rule. Commonly used on lower layers.\n\nArguments:\n\nγ: Optional multiplier for added positive weights, defaults to 0.25.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.IndexNS","page":"Home","title":"ExplainabilityMethods.IndexNS","text":"IndexNS(index)\n\nNeuron selector that picks the output neuron at the given index.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.LRP","page":"Home","title":"ExplainabilityMethods.LRP","text":"LRP(c::Chain, r::AbstractLRPRule)\nLRP(c::Chain, rs::AbstractVector{<:AbstractLRPRule})\nLRP(layers::AbstractVector{LRPLayer})\n\nAnalyzer that applies LRP.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.MaxActivationNS","page":"Home","title":"ExplainabilityMethods.MaxActivationNS","text":"MaxActivationNS()\n\nNeuron selector that picks the output neuron with the highest activation.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.ZBoxRule","page":"Home","title":"ExplainabilityMethods.ZBoxRule","text":"ZBoxRule()\n\nConstructor for LRP-z^{\\mathcal{B}}`-rule. Commonly used on the first layer for pixel input.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.ZeroRule","page":"Home","title":"ExplainabilityMethods.ZeroRule","text":"ZeroRule()\n\nConstructor for LRP-0 rule. Commonly used on upper layers.\n\n\n\n\n\n","category":"type"},{"location":"#ExplainabilityMethods.analyze-Tuple{AbstractArray{var\"#s3\", N} where {var\"#s3\"<:Real, N}, AbstractXAIMethod, Integer, Vararg{Any, N} where N}","page":"Home","title":"ExplainabilityMethods.analyze","text":"analyze(input, method)\nanalyze(input, method, neuron_selection)\n\nReturn raw classifier output and explanation. If neuron_selection is specified, the explanation will be calculated for that neuron. Otherwise, the output neuron with the highest activation is automatically chosen.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.check_ouput_softmax-Tuple{Flux.Chain}","page":"Home","title":"ExplainabilityMethods.check_ouput_softmax","text":"check_ouput_softmax(model)\n\nCheck whether model has softmax activation on output. Return the model if it doesn't, throw error otherwise.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.drop_singleton_dims-Tuple{AbstractArray}","page":"Home","title":"ExplainabilityMethods.drop_singleton_dims","text":"drop_singleton_dims(a)\n\nDrop dimensions of size 1 from array.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.flatten_chain-Tuple{Flux.Chain}","page":"Home","title":"ExplainabilityMethods.flatten_chain","text":"flatten_chain(c)\n\nFlatten a Flux chain containing Flux chains.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.heatmap-Tuple{AbstractArray}","page":"Home","title":"ExplainabilityMethods.heatmap","text":"heatmap(expl; kwargs...)\n\nVisualize explanation.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.modify_denominator-Tuple{AbstractLRPRule, Any}","page":"Home","title":"ExplainabilityMethods.modify_denominator","text":"modify_denominator!(d, rule)\n\nFunction that modifies zₖ on the forward pass, e.g. for numerical stability.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.modify_layer-Tuple{AbstractLRPRule, Any}","page":"Home","title":"ExplainabilityMethods.modify_layer","text":"modify_layer(rule, layer)\n\nApplies modify_params to layer if it has parameters\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.modify_params-Tuple{AbstractLRPRule, Any, Any}","page":"Home","title":"ExplainabilityMethods.modify_params","text":"modify_params!(rule, W, b)\n\nFunction that modifies weights and biases before applying relevance propagation.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.safedivide-Tuple{Any, Any}","page":"Home","title":"ExplainabilityMethods.safedivide","text":"safedivide(a, b; eps = 1f-6)\n\nElementwise division of two matrices avoiding zero terms in the denominator by replacing them with eps.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.set_weights-Tuple{Flux.Conv, Any, Any}","page":"Home","title":"ExplainabilityMethods.set_weights","text":"set_weights(layer, W, b)\n\nDuplicate layer using weights W, b.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.stabilize_denom-Tuple{Any}","page":"Home","title":"ExplainabilityMethods.stabilize_denom","text":"stabilize_denom(d; eps = 1f-6)\n\nReplace zero terms of a matrix d with eps.\n\n\n\n\n\n","category":"method"},{"location":"#ExplainabilityMethods.strip_softmax-Tuple{Flux.Chain}","page":"Home","title":"ExplainabilityMethods.strip_softmax","text":"strip_softmax(model)\n\nRemove softmax activation on model output if it exists.\n\n\n\n\n\n","category":"method"}]
}
