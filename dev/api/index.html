<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · ExplainableAI.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ExplainableAI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ExplainableAI.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../generated/example/">Getting started</a></li><li><a class="tocitem" href="../generated/advanced_lrp/">Advanced LRP</a></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Analyzers"><span>Analyzers</span></a></li><li class="toplevel"><a class="tocitem" href="#LRP"><span>LRP</span></a></li><li><a class="tocitem" href="#Rules"><span>Rules</span></a></li><li><a class="tocitem" href="#Custom-rules"><span>Custom rules</span></a></li><li class="toplevel"><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li><li class="toplevel"><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adrhill/ExplainableAI.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Basics"><a class="docs-heading-anchor" href="#Basics">Basics</a><a id="Basics-1"></a><a class="docs-heading-anchor-permalink" href="#Basics" title="Permalink"></a></h1><p>All methods in ExplainableAI.jl work by calling <code>analyze</code> on an input and an analyzer:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.analyze" href="#ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">analyze(input, method)
analyze(input, method, neuron_selection)</code></pre><p>Return raw classifier output and explanation. If <code>neuron_selection</code> is specified, the explanation will be calculated for that neuron. Otherwise, the output neuron with the highest activation is automatically chosen.</p><p><strong>Keyword arguments</strong></p><ul><li><code>add_batch_dim</code>: add batch dimension to the input without allocating. Default is <code>false</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/analyze_api.jl#L10-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.heatmap" href="#ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">heatmap(expl::Explanation; kwargs...)
heatmap(attr::AbstractArray; kwargs...)

heatmap(input, analyzer::AbstractXAIMethod)
heatmap(input, analyzer::AbstractXAIMethod, neuron_selection::Int)</code></pre><p>Visualize explanation. Assumes Flux&#39;s WHCN convention (width, height, color channels, batch size).</p><p><strong>Keyword arguments</strong></p><ul><li><code>cs::ColorScheme</code>: ColorScheme that is applied.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>ColorSchemes.seismic</code>.</li><li><code>reduce::Symbol</code>: How the color channels are reduced to a single number to apply a colorscheme.   The following methods can be selected, which are then applied over the color channels   for each &quot;pixel&quot; in the attribution:<ul><li><code>:sum</code>: sum up color channels</li><li><code>:norm</code>: compute 2-norm over the color channels</li><li><code>:maxabs</code>: compute <code>maximum(abs, x)</code> over the color channels in</li></ul>When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>:sum</code>.</li><li><code>rangescale::Symbol</code>: How the color channel reduced heatmap is normalized before the colorscheme is applied.   Can be either <code>:extrema</code> or <code>:centered</code>.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default for use with the <code>seismic</code> colorscheme is <code>:centered</code>.</li><li><code>permute::Bool</code>: Whether to flip W&amp;H input channels. Default is <code>true</code>.</li><li><code>unpack_singleton::Bool</code>: When heatmapping a batch with a single sample, setting <code>unpack_singleton=true</code>   will return an image instead of an Vector containing a single image.</li></ul><p><strong>Note:</strong> these keyword arguments can&#39;t be used when calling <code>heatmap</code> with an analyzer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/heatmap.jl#L10-L41">source</a></section></article><h1 id="Analyzers"><a class="docs-heading-anchor" href="#Analyzers">Analyzers</a><a id="Analyzers-1"></a><a class="docs-heading-anchor-permalink" href="#Analyzers" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP" href="#ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LRP(c::Chain, r::AbstractLRPRule)
LRP(c::Chain, rs::AbstractVector{&lt;:AbstractLRPRule})</code></pre><p>Analyze model by applying Layer-Wise Relevance Propagation.</p><p><strong>Keyword arguments</strong></p><ul><li><code>skip_checks::Bool</code>: Skip checks whether model is compatible with LRP and contains output softmax. Default is <code>false</code>.</li><li><code>verbose::Bool</code>: Select whether the model checks should print a summary on failure. Default is <code>true</code>.</li></ul><p><strong>References</strong></p><p>[1] G. Montavon et al., Layer-Wise Relevance Propagation: An Overview [2] W. Samek et al., Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/lrp.jl#L1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.Gradient" href="#ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Gradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/gradient.jl#L18-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.InputTimesGradient" href="#ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InputTimesGradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input. This gradient is then multiplied element-wise with the input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/gradient.jl#L34-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.SmoothGrad" href="#ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SmoothGrad(analyzer, [n=50, std=0.1, rng=GLOBAL_RNG])
SmoothGrad(analyzer, [n=50, distribution=Normal(0, σ²=0.01), rng=GLOBAL_RNG])</code></pre><p>Analyze model by calculating a smoothed sensitivity map. This is done by averaging sensitivity maps of a <code>Gradient</code> analyzer over random samples in a neighborhood of the input, typically by adding Gaussian noise with mean 0.</p><p><strong>References</strong></p><p>[1] Smilkov et al., SmoothGrad: removing noise by adding noise</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/gradient.jl#L53-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.IntegratedGradients" href="#ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IntegratedGradients(analyzer, [n=50])
IntegratedGradients(analyzer, [n=50])</code></pre><p>Analyze model by using the Integrated Gradients method.</p><p><strong>References</strong></p><p>[1] Sundararajan et al., Axiomatic Attribution for Deep Networks</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/gradient.jl#L66-L74">source</a></section></article><p><code>SmoothGrad</code> and <code>IntegratedGradients</code> are special cases of the input augmentation wrappers <code>NoiseAugmentation</code> and <code>InterpolationAugmentation</code>, which can be applied as a wrapper to any analyzer:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.NoiseAugmentation" href="#ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NoiseAugmentation(analyzer, n, [std=1, rng=GLOBAL_RNG])
NoiseAugmentation(analyzer, n, distribution, [rng=GLOBAL_RNG])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> samples of additive noise sampled from <code>distribution</code>. This input augmentation is then averaged to return an <code>Explanation</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/input_augmentation.jl#L75-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.InterpolationAugmentation" href="#ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InterpolationAugmentation(model, [n=50])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> steps of linear interpolation between the input and a reference input (typically <code>zero(input)</code>). The gradients w.r.t. this augmented input are then averaged and multiplied with the difference between the input and the reference input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/input_augmentation.jl#L120-L127">source</a></section></article><h1 id="LRP"><a class="docs-heading-anchor" href="#LRP">LRP</a><a id="LRP-1"></a><a class="docs-heading-anchor-permalink" href="#LRP" title="Permalink"></a></h1><h2 id="Rules"><a class="docs-heading-anchor" href="#Rules">Rules</a><a id="Rules-1"></a><a class="docs-heading-anchor-permalink" href="#Rules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.ZeroRule" href="#ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZeroRule()</code></pre><p>LRP-0 rule. Commonly used on upper layers.</p><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L106-L114">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonRule" href="#ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EpsilonRule([ϵ=1.0f-6])</code></pre><p>LRP-<span>$ϵ$</span> rule. Commonly used on middle layers.</p><p>Arguments:</p><ul><li><code>ϵ</code>: Optional stabilization parameter, defaults to <code>1f-6</code>.</li></ul><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L121-L132">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.GammaRule" href="#ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaRule([γ=0.25])</code></pre><p>LRP-<span>$γ$</span> rule. Commonly used on lower layers.</p><p>Arguments:</p><ul><li><code>γ</code>: Optional multiplier for added positive weights, defaults to <code>0.25</code>.</li></ul><p><strong>References</strong></p><p>[1]: G. Montavon et al., Layer-Wise Relevance Propagation: An Overview</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L143-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.WSquareRule" href="#ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WSquareRule()</code></pre><p>LRP-<span>$W^2$</span> rule. Commonly used on the first layer when values are unbounded.</p><p><strong>References</strong></p><p>[1]: G. Montavon et al., Explaining nonlinear classification decisions with deep Taylor decomposition</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L164-L171">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.AlphaBetaRule" href="#ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AlphaBetaRule(alpha, beta)
AlphaBetaRule([alpha=2.0], [beta=1.0])</code></pre><p>LRP-<span>$lphaeta$</span> rule. Weights positive and negative contributions according to the parameters <code>alpha</code> and <code>beta</code> respectively. The difference <code>alpha - beta</code> must be equal one. Commonly used on lower layers.</p><p>Arguments:</p><ul><li><code>alpha</code>: Multiplier for the positive output term, defaults to <code>2.0</code>.</li><li><code>beta</code>: Multiplier for the negative output term, defaults to <code>1.0</code>.</li></ul><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation [2]: G. Montavon et al., Layer-Wise Relevance Propagation: An Overview</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L254-L270">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.FlatRule" href="#ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FlatRule()</code></pre><p>LRP-Flat rule. Similar to the <a href="#ExplainableAI.WSquareRule"><code>WSquareRule</code></a>, but with all parameters set to one.</p><p><strong>References</strong></p><p>[1]: S. Lapuschkin et al., Unmasking Clever Hans predictors and assessing what machines really learn</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L176-L183">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.ZBoxRule" href="#ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZBoxRule(low, high)</code></pre><p>LRP-<span>$z^{\mathcal{B}}$</span>-rule. Commonly used on the first layer for pixel input.</p><p>The parameters <code>low</code> and <code>high</code> should be set to the lower and upper bounds of the input features, e.g. <code>0.0</code> and <code>1.0</code> for raw image data. It is also possible to provide two arrays of that match the input size.</p><p><strong>References</strong></p><p>[1]: G. Montavon et al., Explaining nonlinear classification decisions with deep Taylor decomposition</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L205-L216">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.PassRule" href="#ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PassRule()</code></pre><p>Pass-through rule. Passes relevance through to the lower layer. Supports reshaping layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L188-L193">source</a></section></article><h2 id="Custom-rules"><a class="docs-heading-anchor" href="#Custom-rules">Custom rules</a><a id="Custom-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-rules" title="Permalink"></a></h2><p>These utilities can be used to define custom rules without writing boilerplate code:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_input" href="#ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_input(rule, input)</code></pre><p>Modify input activation before computing relevance propagation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L24-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_denominator" href="#ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_denominator(rule, d)</code></pre><p>Modify denominator <span>$z$</span> for numerical stability on the forward pass.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L31-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_param!" href="#ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_param!(rule, W)
modify_param!(rule, b)</code></pre><p>Inplace-modify parameters before computing the relevance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L73-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_layer!" href="#ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_layer!(rule, layer; ignore_bias=false)</code></pre><p>In-place modify layer parameters by calling <code>modify_param!</code> before computing relevance propagation.</p><p><strong>Note</strong></p><p>When implementing a custom <code>modify_layer!</code> function, <code>modify_param!</code> will not be called.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/rules.jl#L49-L57">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>check_compat</code>. Check Documenter&#39;s build log for details.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP_CONFIG.supports_layer" href="#ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(layer)</code></pre><p>Check whether LRP can be used on a layer or a Chain. To extend LRP to your own layers, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::MyLayer) = true          # for structs
LRP_CONFIG.supports_layer(::typeof(mylayer)) = true  # for functions</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/checks.jl#L4-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP_CONFIG.supports_activation" href="#ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(σ)</code></pre><p>Check whether LRP can be used on a given activation function. To extend LRP to your own activation functions, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(::typeof(myactivation)) = true  # for functions
LRP_CONFIG.supports_activation(::MyActivation) = true          # for structs</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/checks.jl#L16-L25">source</a></section></article><h1 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.strip_softmax" href="#ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">strip_softmax(model)</code></pre><p>Remove softmax activation on model output if it exists.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/flux_utils.jl#L47-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.flatten_model" href="#ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">flatten_model(c)</code></pre><p>Flatten a Flux chain containing Flux chains.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/flux_utils.jl#L12-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.canonize" href="#ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">canonize(model)</code></pre><p>Canonize model by flattening it and fusing BatchNorm layers into preceding Dense and Conv layers with linear activation functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/084c9623a55c7937f5760cef254a1ee4e0f46564/src/lrp/canonize.jl#L37-L42">source</a></section></article><h1 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h1><ul><li><a href="#ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a></li><li><a href="#ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a></li><li><a href="#ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a></li><li><a href="#ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a></li><li><a href="#ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a></li><li><a href="#ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a></li><li><a href="#ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a></li><li><a href="#ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a></li><li><a href="#ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a></li><li><a href="#ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a></li><li><a href="#ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a></li><li><a href="#ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a></li><li><a href="#ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a></li><li><a href="#ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a></li><li><a href="#ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a></li><li><a href="#ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a></li><li><a href="#ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a></li><li><a href="#ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a></li><li><a href="#ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a></li><li><a href="#ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a></li><li><a href="#ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a></li><li><a href="#ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a></li><li><a href="#ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a></li><li><a href="#ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../generated/advanced_lrp/">« Advanced LRP</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Friday 5 August 2022 12:58">Friday 5 August 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
