{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom LRP rules\n",
    "One of the design goals of ExplainableAI.jl is to combine ease of use and\n",
    "extensibility for the purpose of research."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example will show you how to implement custom LRP rules.\n",
    "building on the basics shown in the *Getting started* section.\n",
    "\n",
    "We start out by loading the same pre-trained LeNet5 model and MNIST input data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((5, 5), 1 => 6, relu),           \u001b[90m# 156 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((5, 5), 6 => 16, relu),          \u001b[90m# 2_416 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Flux.flatten,\n  Dense(256 => 120, relu),              \u001b[90m# 30_840 parameters\u001b[39m\n  Dense(120 => 84, relu),               \u001b[90m# 10_164 parameters\u001b[39m\n  Dense(84 => 10),                      \u001b[90m# 850 parameters\u001b[39m\n) \u001b[90m                  # Total: 10 arrays, \u001b[39m44_426 parameters, 174.867 KiB."
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "using ExplainableAI\n",
    "using Flux\n",
    "using MLDatasets\n",
    "using ImageCore\n",
    "using BSON\n",
    "\n",
    "index = 10\n",
    "x, y = MNIST(Float32, :test)[10]\n",
    "input = reshape(x, 28, 28, 1, :)\n",
    "\n",
    "model = BSON.load(\"../../model.bson\", @__MODULE__)[:model] # hide\n",
    "model"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing a custom rule\n",
    "### Step 1: Define rule struct\n",
    "Let's define a rule that modifies the weights and biases of our layer on the forward pass.\n",
    "The rule has to be of supertype `AbstractLRPRule`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct MyGammaRule <: AbstractLRPRule end"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Implement rule behavior\n",
    "It is then possible to dispatch on the following four utility functions\n",
    "with the rule type `MyCustomLRPRule` to define custom rules without writing boilerplate code.\n",
    "\n",
    "1. `modify_input(rule::MyGammaRule, input)`\n",
    "1. `modify_parameters(rule::MyGammaRule, parameter)`\n",
    "1. `modify_denominator(rule::MyGammaRule, denominator)`\n",
    "1. `is_compatible(rule::MyGammaRule, layer)`\n",
    "\n",
    "By default:\n",
    "1. `modify_input` doesn't change the input\n",
    "1. `modify_parameters` doesn't change the parameters\n",
    "1. `modify_denominator` avoids division by zero by adding a small epsilon-term (`1.0f-9`)\n",
    "1. `is_compatible` returns `true` if a layer has fields `weight` and `bias`\n",
    "\n",
    "To extend internal functions, import them explicitly:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "modify_parameters (generic function with 6 methods)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "import ExplainableAI: modify_parameters\n",
    "\n",
    "modify_parameters(::MyGammaRule, param) = param + 0.25f0 * relu.(param)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we didn't implement three of the four functions.\n",
    "This is because the defaults are sufficient to implement the `GammaRule`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Use rule in LRP analyzer\n",
    "We can directly use our rule to make an analyzer!"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28×28 Array{RGB{Float64},2} with eltype ColorTypes.RGB{Float64}:\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n ⋮                          ⋱  \n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA9ZJREFUeAHtwb9r1Hccx/Hn9+5154+7M8o1p/Zq4y+K9Vfw4Ci6CiLBSXEoaF2zCU7iPyGIs5uDuHQxg1O2NogiklDSJaHWNLUmVnPYaON9O33eLi6Gt5dLeT8eyvOc4EcEVyK4EsGVCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGV6GfLy5g8x4yPY5484aNGR0lWKgMkEp+VCK5EcCWCK9EPul3MwgJmagozOYkpFDCzs5hqFTM2RqJWC7NnD8mL12WSeh2TZayaCK5EcCWCK9FDKyuYLMMU/3mDmZvDFAqYVgvz4gWm3cbMzWEmJjBTU5jLl0m+2LKFZKmzgaRWY9VEcCWCKxFcic9tfp5EnQ6mUiHpbt9JUqhWMUNDmIEBTJbxUWNjmGvXMI8eYW7fxpw+TVJrNknyvEaSZXwSEVyJ4EoEV8JJnmOyZ79jCgWSl/X9JKUSpvqmg9m3j1XbuRMjYVotTKOBefUKs2MHSZZ3MVmBTyGCKxFcieBKOOl2MSuDX5Fs+PEOybZqFTMygsmqfJI8x7x9i2k0MI8fY7KMpHPoO5J/t2O2DmCyjFUTwZUIrkRwJZwU378jKf78E+bWLcyDB5j79zE3b2IePsScO4dZXMQMDmJmZjCDg5gDBzAHD5JU6ZD8+leVpFLBlMusmgiuRHAlgivhpVTCzM5iJidJ7r98SfJLu03yNx/s44PvJydJJvjgxPAwZmgIMz2NyTJMvY45doxk716MhAsRXIngSgRXwkuWYS5dwpw/T3Lq6lWSU+PjmOlpzMgI5sgRkhNjY5jlZT7q+XNMt4sZHsaUSiTKcCeCKxFcieBKfG6bN2Nu3GDVdu/GXL+OKRQwFy9iRkcxjQa9IoIrEVyJ4Er0s6UlTJZhLlzA1GqYs2cxjQZrQQRXIrgSwZXoM9PTmHv3aiRXLv+AmZ/HbN2KqVRYayK4EsGVCK5EH1hawty5gzl5EjP7tEjy+nWT5NsGpsTaE8GVCK5EcCX6QK3SJWm3CyR5jllYwBw6hCmV6CsiuBLBlQiuxFrpdkn++LNAcvcupt3GnDmD2biRviWCKxFcieBK9NL79yS/PSuSdDqYo0cxQ0OYXbtYF0RwJYIrEVyJXnr6lOTrcpnk3syXJMePY/bvZ90RwZUIrkRwJXppcZGk802LpNHAHD6M2bSJdUcEVyK4EsGV6KVt20iqVUy9jimXWddEcCWCKxFciV5qNknevcM0m5hikXVNBFciuBLBleilcpmkzP+TCK5EcCWCq/8Ae4S2RofAotIAAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA9ZJREFUeAHtwb9r1Hccx/Hn9+5154+7M8o1p/Zq4y+K9Vfw4Ci6CiLBSXEoaF2zCU7iPyGIs5uDuHQxg1O2NogiklDSJaHWNLUmVnPYaON9O33eLi6Gt5dLeT8eyvOc4EcEVyK4EsGVCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGV6GfLy5g8x4yPY5484aNGR0lWKgMkEp+VCK5EcCWCK9EPul3MwgJmagozOYkpFDCzs5hqFTM2RqJWC7NnD8mL12WSeh2TZayaCK5EcCWCK9FDKyuYLMMU/3mDmZvDFAqYVgvz4gWm3cbMzWEmJjBTU5jLl0m+2LKFZKmzgaRWY9VEcCWCKxFcic9tfp5EnQ6mUiHpbt9JUqhWMUNDmIEBTJbxUWNjmGvXMI8eYW7fxpw+TVJrNknyvEaSZXwSEVyJ4EoEV8JJnmOyZ79jCgWSl/X9JKUSpvqmg9m3j1XbuRMjYVotTKOBefUKs2MHSZZ3MVmBTyGCKxFcieBKOOl2MSuDX5Fs+PEOybZqFTMygsmqfJI8x7x9i2k0MI8fY7KMpHPoO5J/t2O2DmCyjFUTwZUIrkRwJZwU378jKf78E+bWLcyDB5j79zE3b2IePsScO4dZXMQMDmJmZjCDg5gDBzAHD5JU6ZD8+leVpFLBlMusmgiuRHAlgivhpVTCzM5iJidJ7r98SfJLu03yNx/s44PvJydJJvjgxPAwZmgIMz2NyTJMvY45doxk716MhAsRXIngSgRXwkuWYS5dwpw/T3Lq6lWSU+PjmOlpzMgI5sgRkhNjY5jlZT7q+XNMt4sZHsaUSiTKcCeCKxFcieBKfG6bN2Nu3GDVdu/GXL+OKRQwFy9iRkcxjQa9IoIrEVyJ4Er0s6UlTJZhLlzA1GqYs2cxjQZrQQRXIrgSwZXoM9PTmHv3aiRXLv+AmZ/HbN2KqVRYayK4EsGVCK5EH1hawty5gzl5EjP7tEjy+nWT5NsGpsTaE8GVCK5EcCX6QK3SJWm3CyR5jllYwBw6hCmV6CsiuBLBlQiuxFrpdkn++LNAcvcupt3GnDmD2biRviWCKxFcieBK9NL79yS/PSuSdDqYo0cxQ0OYXbtYF0RwJYIrEVyJXnr6lOTrcpnk3syXJMePY/bvZ90RwZUIrkRwJXppcZGk802LpNHAHD6M2bSJdUcEVyK4EsGV6KVt20iqVUy9jimXWddEcCWCKxFciV5qNknevcM0m5hikXVNBFciuBLBleilcpmkzP+TCK5EcCWCq/8Ae4S2RofAotIAAAAASUVORK5C\">"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "rules = [\n",
    "    ZPlusRule(),\n",
    "    EpsilonRule(),\n",
    "    MyGammaRule(), # our custom GammaRule\n",
    "    EpsilonRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "]\n",
    "analyzer = LRP(model, rules)\n",
    "heatmap(input, analyzer)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "We just implemented our own version of the $γ$-rule in 2 lines of code.\n",
    "The heatmap perfectly matches the pre-implemented `GammaRule`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28×28 Array{RGB{Float64},2} with eltype ColorTypes.RGB{Float64}:\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n ⋮                          ⋱  \n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA9ZJREFUeAHtwb9r1Hccx/Hn9+5154+7M8o1p/Zq4y+K9Vfw4Ci6CiLBSXEoaF2zCU7iPyGIs5uDuHQxg1O2NogiklDSJaHWNLUmVnPYaON9O33eLi6Gt5dLeT8eyvOc4EcEVyK4EsGVCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGV6GfLy5g8x4yPY5484aNGR0lWKgMkEp+VCK5EcCWCK9EPul3MwgJmagozOYkpFDCzs5hqFTM2RqJWC7NnD8mL12WSeh2TZayaCK5EcCWCK9FDKyuYLMMU/3mDmZvDFAqYVgvz4gWm3cbMzWEmJjBTU5jLl0m+2LKFZKmzgaRWY9VEcCWCKxFcic9tfp5EnQ6mUiHpbt9JUqhWMUNDmIEBTJbxUWNjmGvXMI8eYW7fxpw+TVJrNknyvEaSZXwSEVyJ4EoEV8JJnmOyZ79jCgWSl/X9JKUSpvqmg9m3j1XbuRMjYVotTKOBefUKs2MHSZZ3MVmBTyGCKxFcieBKOOl2MSuDX5Fs+PEOybZqFTMygsmqfJI8x7x9i2k0MI8fY7KMpHPoO5J/t2O2DmCyjFUTwZUIrkRwJZwU378jKf78E+bWLcyDB5j79zE3b2IePsScO4dZXMQMDmJmZjCDg5gDBzAHD5JU6ZD8+leVpFLBlMusmgiuRHAlgivhpVTCzM5iJidJ7r98SfJLu03yNx/s44PvJydJJvjgxPAwZmgIMz2NyTJMvY45doxk716MhAsRXIngSgRXwkuWYS5dwpw/T3Lq6lWSU+PjmOlpzMgI5sgRkhNjY5jlZT7q+XNMt4sZHsaUSiTKcCeCKxFcieBKfG6bN2Nu3GDVdu/GXL+OKRQwFy9iRkcxjQa9IoIrEVyJ4Er0s6UlTJZhLlzA1GqYs2cxjQZrQQRXIrgSwZXoM9PTmHv3aiRXLv+AmZ/HbN2KqVRYayK4EsGVCK5EH1hawty5gzl5EjP7tEjy+nWT5NsGpsTaE8GVCK5EcCX6QK3SJWm3CyR5jllYwBw6hCmV6CsiuBLBlQiuxFrpdkn++LNAcvcupt3GnDmD2biRviWCKxFcieBK9NL79yS/PSuSdDqYo0cxQ0OYXbtYF0RwJYIrEVyJXnr6lOTrcpnk3syXJMePY/bvZ90RwZUIrkRwJXppcZGk802LpNHAHD6M2bSJdUcEVyK4EsGV6KVt20iqVUy9jimXWddEcCWCKxFciV5qNknevcM0m5hikXVNBFciuBLBleilcpmkzP+TCK5EcCWCq/8Ae4S2RofAotIAAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA9ZJREFUeAHtwb9r1Hccx/Hn9+5154+7M8o1p/Zq4y+K9Vfw4Ci6CiLBSXEoaF2zCU7iPyGIs5uDuHQxg1O2NogiklDSJaHWNLUmVnPYaON9O33eLi6Gt5dLeT8eyvOc4EcEVyK4EsGVCK5EcCWCKxFcieBKBFciuBLBlQiuRHAlgisRXIngSgRXIrgSwZUIrkRwJYIrEVyJ4EoEVyK4EsGV6GfLy5g8x4yPY5484aNGR0lWKgMkEp+VCK5EcCWCK9EPul3MwgJmagozOYkpFDCzs5hqFTM2RqJWC7NnD8mL12WSeh2TZayaCK5EcCWCK9FDKyuYLMMU/3mDmZvDFAqYVgvz4gWm3cbMzWEmJjBTU5jLl0m+2LKFZKmzgaRWY9VEcCWCKxFcic9tfp5EnQ6mUiHpbt9JUqhWMUNDmIEBTJbxUWNjmGvXMI8eYW7fxpw+TVJrNknyvEaSZXwSEVyJ4EoEV8JJnmOyZ79jCgWSl/X9JKUSpvqmg9m3j1XbuRMjYVotTKOBefUKs2MHSZZ3MVmBTyGCKxFcieBKOOl2MSuDX5Fs+PEOybZqFTMygsmqfJI8x7x9i2k0MI8fY7KMpHPoO5J/t2O2DmCyjFUTwZUIrkRwJZwU378jKf78E+bWLcyDB5j79zE3b2IePsScO4dZXMQMDmJmZjCDg5gDBzAHD5JU6ZD8+leVpFLBlMusmgiuRHAlgivhpVTCzM5iJidJ7r98SfJLu03yNx/s44PvJydJJvjgxPAwZmgIMz2NyTJMvY45doxk716MhAsRXIngSgRXwkuWYS5dwpw/T3Lq6lWSU+PjmOlpzMgI5sgRkhNjY5jlZT7q+XNMt4sZHsaUSiTKcCeCKxFcieBKfG6bN2Nu3GDVdu/GXL+OKRQwFy9iRkcxjQa9IoIrEVyJ4Er0s6UlTJZhLlzA1GqYs2cxjQZrQQRXIrgSwZXoM9PTmHv3aiRXLv+AmZ/HbN2KqVRYayK4EsGVCK5EH1hawty5gzl5EjP7tEjy+nWT5NsGpsTaE8GVCK5EcCX6QK3SJWm3CyR5jllYwBw6hCmV6CsiuBLBlQiuxFrpdkn++LNAcvcupt3GnDmD2biRviWCKxFcieBK9NL79yS/PSuSdDqYo0cxQ0OYXbtYF0RwJYIrEVyJXnr6lOTrcpnk3syXJMePY/bvZ90RwZUIrkRwJXppcZGk802LpNHAHD6M2bSJdUcEVyK4EsGV6KVt20iqVUy9jimXWddEcCWCKxFciV5qNknevcM0m5hikXVNBFciuBLBleilcpmkzP+TCK5EcCWCq/8Ae4S2RofAotIAAAAASUVORK5C\">"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "rules = [\n",
    "    ZPlusRule(),\n",
    "    EpsilonRule(),\n",
    "    GammaRule(), # XAI.jl's GammaRule\n",
    "    EpsilonRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "    ZeroRule(),\n",
    "]\n",
    "analyzer = LRP(model, rules)\n",
    "heatmap(input, analyzer)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance tips\n",
    "1. Make sure functions like `modify_parameters` don't promote the type of weights\n",
    "   (e.g. from `Float32` to `Float64`).\n",
    "2. If your rule `MyRule` doesn't modify weights or biases,\n",
    "   defining `modify_layer(::MyRule, layer) = nothing`\n",
    "   can provide reduce memory allocations and improve performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced layer modification\n",
    "For more granular control over weights and biases,\n",
    "`modify_weight` and\n",
    "`modify_bias` can be used.\n",
    "\n",
    "If the layer doesn't use weights (`layer.weight`) and biases (`layer.bias`),\n",
    "ExplainableAI provides a lower-level variant of\n",
    "`modify_parameters` called\n",
    "`modify_layer`.\n",
    "This function is expected to take a layer and return a new, modified layer.\n",
    "To add compatibility checks between rule and layer types, extend\n",
    "`is_compatible`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced LRP rules\n",
    "To implement custom LRP rules that require more than `modify_layer`, `modify_input`\n",
    "and `modify_denominator`, take a look at the LRP developer documentation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
