<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · ExplainableAI.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ExplainableAI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ExplainableAI.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../generated/example/">Getting started</a></li><li><a class="tocitem" href="../generated/advanced_lrp/">Advanced LRP</a></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Analyzers"><span>Analyzers</span></a></li><li class="toplevel"><a class="tocitem" href="#Layer-wise-Relevance-Propagation"><span>Layer-wise Relevance Propagation</span></a></li><li><a class="tocitem" href="#LRP-rules"><span>LRP rules</span></a></li><li><a class="tocitem" href="#Custom-rules"><span>Custom rules</span></a></li><li><a class="tocitem" href="#Composites"><span>Composites</span></a></li><li class="toplevel"><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li><li class="toplevel"><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adrhill/ExplainableAI.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Basics"><a class="docs-heading-anchor" href="#Basics">Basics</a><a id="Basics-1"></a><a class="docs-heading-anchor-permalink" href="#Basics" title="Permalink"></a></h1><p>All methods in ExplainableAI.jl work by calling <code>analyze</code> on an input and an analyzer:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.analyze" href="#ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">analyze(input, method)
analyze(input, method, neuron_selection)</code></pre><p>Return an <a href="#ExplainableAI.Explanation"><code>Explanation</code></a> containing the attribution and the raw classifier output. If <code>neuron_selection</code> is specified, the explanation will be calculated for that neuron. Otherwise, the output neuron with the highest activation is automatically chosen.</p><p><strong>Keyword arguments</strong></p><ul><li><code>add_batch_dim</code>: add batch dimension to the input without allocating. Default is <code>false</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/analyze_api.jl#L10-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.Explanation" href="#ExplainableAI.Explanation"><code>ExplainableAI.Explanation</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Return type of analyzers when calling <code>analyze</code>.</p><p>Contains:</p><ul><li><code>attribution</code>: the analyzer&#39;s attribution</li><li><code>output</code>: the model output</li><li><code>neuron_selection</code>: the neuron index used for the attribution</li><li><code>analyzer</code>: a symbol corresponding the used analyzer, e.g. <code>:LRP</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/analyze_api.jl#L60-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.heatmap" href="#ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">heatmap(explanation)
heatmap(input, analyzer)
heatmap(input, analyzer, neuron_selection)</code></pre><p>Visualize explanation. Assumes Flux&#39;s WHCN convention (width, height, color channels, batch size).</p><p><strong>Keyword arguments</strong></p><ul><li><code>cs::ColorScheme</code>: ColorScheme that is applied.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>ColorSchemes.seismic</code>.</li><li><code>reduce::Symbol</code>: How the color channels are reduced to a single number to apply a colorscheme.   The following methods can be selected, which are then applied over the color channels   for each &quot;pixel&quot; in the attribution:<ul><li><code>:sum</code>: sum up color channels</li><li><code>:norm</code>: compute 2-norm over the color channels</li><li><code>:maxabs</code>: compute <code>maximum(abs, x)</code> over the color channels in</li></ul>When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>:sum</code>.</li><li><code>rangescale::Symbol</code>: How the color channel reduced heatmap is normalized before the colorscheme is applied.   Can be either <code>:extrema</code> or <code>:centered</code>.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default for use with the <code>seismic</code> colorscheme is <code>:centered</code>.</li><li><code>permute::Bool</code>: Whether to flip W&amp;H input channels. Default is <code>true</code>.</li><li><code>unpack_singleton::Bool</code>: When heatmapping a batch with a single sample, setting <code>unpack_singleton=true</code>   will return an image instead of an Vector containing a single image.</li></ul><p><strong>Note:</strong> keyword arguments can&#39;t be used when calling <code>heatmap</code> with an analyzer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/heatmap.jl#L10-L39">source</a></section></article><h1 id="Analyzers"><a class="docs-heading-anchor" href="#Analyzers">Analyzers</a><a id="Analyzers-1"></a><a class="docs-heading-anchor-permalink" href="#Analyzers" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP" href="#ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LRP(model, rules)
LRP(model, composite)</code></pre><p>Analyze model by applying Layer-Wise Relevance Propagation. The analyzer can either be created by passing an array of LRP-rules or by passing a composite, see <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p><p><strong>Keyword arguments</strong></p><ul><li><code>skip_checks::Bool</code>: Skip checks whether model is compatible with LRP and contains output softmax. Default is <code>false</code>.</li><li><code>verbose::Bool</code>: Select whether the model checks should print a summary on failure. Default is <code>true</code>.</li></ul><p><strong>References</strong></p><p>[1] G. Montavon et al., Layer-Wise Relevance Propagation: An Overview [2] W. Samek et al., Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/lrp.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.Gradient" href="#ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Gradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/gradient.jl#L18-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.InputTimesGradient" href="#ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InputTimesGradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input. This gradient is then multiplied element-wise with the input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/gradient.jl#L34-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.SmoothGrad" href="#ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SmoothGrad(analyzer, [n=50, std=0.1, rng=GLOBAL_RNG])
SmoothGrad(analyzer, [n=50, distribution=Normal(0, σ²=0.01), rng=GLOBAL_RNG])</code></pre><p>Analyze model by calculating a smoothed sensitivity map. This is done by averaging sensitivity maps of a <code>Gradient</code> analyzer over random samples in a neighborhood of the input, typically by adding Gaussian noise with mean 0.</p><p><strong>References</strong></p><p>[1] Smilkov et al., SmoothGrad: removing noise by adding noise</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/gradient.jl#L53-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.IntegratedGradients" href="#ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IntegratedGradients(analyzer, [n=50])
IntegratedGradients(analyzer, [n=50])</code></pre><p>Analyze model by using the Integrated Gradients method.</p><p><strong>References</strong></p><p>[1] Sundararajan et al., Axiomatic Attribution for Deep Networks</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/gradient.jl#L66-L74">source</a></section></article><p><code>SmoothGrad</code> and <code>IntegratedGradients</code> are special cases of the input augmentation wrappers <code>NoiseAugmentation</code> and <code>InterpolationAugmentation</code>, which can be applied as a wrapper to any analyzer:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.NoiseAugmentation" href="#ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NoiseAugmentation(analyzer, n, [std=1, rng=GLOBAL_RNG])
NoiseAugmentation(analyzer, n, distribution, [rng=GLOBAL_RNG])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> samples of additive noise sampled from <code>distribution</code>. This input augmentation is then averaged to return an <code>Explanation</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/input_augmentation.jl#L75-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.InterpolationAugmentation" href="#ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InterpolationAugmentation(model, [n=50])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> steps of linear interpolation between the input and a reference input (typically <code>zero(input)</code>). The gradients w.r.t. this augmented input are then averaged and multiplied with the difference between the input and the reference input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/input_augmentation.jl#L120-L127">source</a></section></article><h1 id="Layer-wise-Relevance-Propagation"><a class="docs-heading-anchor" href="#Layer-wise-Relevance-Propagation">Layer-wise Relevance Propagation</a><a id="Layer-wise-Relevance-Propagation-1"></a><a class="docs-heading-anchor-permalink" href="#Layer-wise-Relevance-Propagation" title="Permalink"></a></h1><h2 id="LRP-rules"><a class="docs-heading-anchor" href="#LRP-rules">LRP rules</a><a id="LRP-rules-1"></a><a class="docs-heading-anchor-permalink" href="#LRP-rules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.ZeroRule" href="#ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZeroRule()</code></pre><p>LRP-<span>$0$</span> rule. Commonly used on upper layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i \frac{w_{ij}a_j^k}{\sum_l w_{il}a_l^k+b_i} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L113-L126">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonRule" href="#ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EpsilonRule([ϵ=1.0f-6])</code></pre><p>LRP-<span>$ϵ$</span> rule. Commonly used on middle layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{w_{ij}a_j^k}{\epsilon +\sum_{l}w_{il}a_l^k+b_i} R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>ϵ</code>: Optional stabilization parameter, defaults to <code>1f-6</code>.</li></ul><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L133-L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.GammaRule" href="#ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaRule([γ=0.25])</code></pre><p>LRP-<span>$γ$</span> rule. Commonly used on lower layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{(w_{ij}+\gamma w_{ij}^+)a_j^k}
    {\sum_l(w_{il}+\gamma w_{il}^+)a_l^k+b_i} R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>γ</code>: Optional multiplier for added positive weights, defaults to <code>0.25</code>.</li></ul><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L160-L177">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.WSquareRule" href="#ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WSquareRule()</code></pre><p>LRP-<span>$w²$</span> rule. Commonly used on the first layer when values are unbounded.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{w_{ij}^2}{\sum_l w_{il}^2} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Explaining Nonlinear Classification Decisions with Deep Taylor Decomposition</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L188-L201">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.FlatRule" href="#ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FlatRule()</code></pre><p>LRP-Flat rule. Similar to the <a href="#ExplainableAI.WSquareRule"><code>WSquareRule</code></a>, but with all weights set to one and all bias terms set to zero.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{1}{\sum_l 1} R_i^{k+1} = \frac{1}{n}\sum_i R_i^{k+1}\]</p><p>where <span>$n$</span> is the number of input neurons connected to the output neuron at index <span>$i$</span>.</p><p><strong>References</strong></p><ul><li>S. Lapuschkin et al., <em>Unmasking Clever Hans predictors and assessing what machines really learn</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L207-L222">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.AlphaBetaRule" href="#ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AlphaBetaRule([α=2.0], [β=1.0])</code></pre><p>LRP-<span>$αβ$</span> rule. Weights positive and negative contributions according to the parameters <code>α</code> and <code>β</code> respectively. The difference <code>α-β</code> must be equal to one. Commonly used on lower layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\left(
    \alpha\frac{\left(w_{ij}a_j^k\right)^+}{\sum_l\left(w_{il}a_l^k+b_i\right)^+}
    -\beta\frac{\left(w_{ij}a_j^k\right)^-}{\sum_l\left(w_{il}a_l^k+b_i\right)^-}
\right) R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>α</code>: Multiplier for the positive output term, defaults to <code>2.0</code>.</li><li><code>β</code>: Multiplier for the negative output term, defaults to <code>1.0</code>.</li></ul><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L313-L336">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.ZPlusRule" href="#ExplainableAI.ZPlusRule"><code>ExplainableAI.ZPlusRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZPlusRule()</code></pre><p>LRP-<span>$z⁺$</span> rule. Commonly used on lower layers.</p><p>Equivalent to <code>AlphaBetaRule(1.0f0, 0.0f0)</code>, but slightly faster. See also <a href="#ExplainableAI.AlphaBetaRule"><code>AlphaBetaRule</code></a>.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{\left(w_{ij}a_j^k\right)^+}{\sum_l\left(w_{il}a_l^k+b_i\right)^+} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li><li>G. Montavon et al., <em>Explaining Nonlinear Classification Decisions with Deep Taylor Decomposition</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L386-L403">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.ZBoxRule" href="#ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZBoxRule(low, high)</code></pre><p>LRP-<span>$zᴮ$</span>-rule. Commonly used on the first layer for pixel input.</p><p>The parameters <code>low</code> and <code>high</code> should be set to the lower and upper bounds of the input features, e.g. <code>0.0</code> and <code>1.0</code> for raw image data. It is also possible to provide two arrays of that match the input size.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k=\sum_i \frac{w_{ij}a_j^k - w_{ij}^{+}l_j - w_{ij}^{-}h_j}
    {\sum_l w_{il}a_l^k+b_i - \left(w_{il}^{+}l_l+b_i^{+}\right) - \left(w_{il}^{-}h_l+b_i^{-}\right)} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L252-L270">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.PassRule" href="#ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PassRule()</code></pre><p>Pass-through rule. Passes relevance through to the lower layer.</p><p>Supports layers with constant input and output shapes, e.g. reshaping layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = R_j^{k+1}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L228-L240">source</a></section></article><h2 id="Custom-rules"><a class="docs-heading-anchor" href="#Custom-rules">Custom rules</a><a id="Custom-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-rules" title="Permalink"></a></h2><p>These utilities can be used to define custom rules without writing boilerplate code:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_input" href="#ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_input(rule, input)</code></pre><p>Modify input activation before computing relevance propagation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L31-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_denominator" href="#ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_denominator(rule, d)</code></pre><p>Modify denominator <span>$z$</span> for numerical stability on the forward pass.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L38-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_param!" href="#ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_param!(rule, W)
modify_param!(rule, b)</code></pre><p>Inplace-modify parameters before computing the relevance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L80-L85">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.modify_layer!" href="#ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_layer!(rule, layer; ignore_bias=false)</code></pre><p>In-place modify layer parameters by calling <code>modify_param!</code> before computing relevance propagation.</p><p><strong>Note</strong></p><p>When implementing a custom <code>modify_layer!</code> function, <code>modify_param!</code> will not be called.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L56-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.check_compat" href="#ExplainableAI.check_compat"><code>ExplainableAI.check_compat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">check_compat(rule, layer)</code></pre><p>Check compatibility of a LRP-Rule with layer type.</p><p><strong>Note</strong></p><p>When implementing a custom <code>check_compat</code> function, return <code>nothing</code> if checks passed, otherwise throw an <code>ArgumentError</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/rules.jl#L45-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP_CONFIG.supports_layer" href="#ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(layer)</code></pre><p>Check whether LRP can be used on a layer or a Chain. To extend LRP to your own layers, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::MyLayer) = true          # for structs
LRP_CONFIG.supports_layer(::typeof(mylayer)) = true  # for functions</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/checks.jl#L4-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LRP_CONFIG.supports_activation" href="#ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(σ)</code></pre><p>Check whether LRP can be used on a given activation function. To extend LRP to your own activation functions, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(::typeof(myactivation)) = true  # for functions
LRP_CONFIG.supports_activation(::MyActivation) = true          # for structs</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/checks.jl#L16-L25">source</a></section></article><h2 id="Composites"><a class="docs-heading-anchor" href="#Composites">Composites</a><a id="Composites-1"></a><a class="docs-heading-anchor-permalink" href="#Composites" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.Composite" href="#ExplainableAI.Composite"><code>ExplainableAI.Composite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Composite([default_rule=LRPZero()], primitives...)</code></pre><p>Automatically contructs a list of LRP-rules by sequentially applying composite primitives.</p><p><strong>Primitives</strong></p><p>To apply a single rule, use:</p><ul><li><a href="#ExplainableAI.LayerRule"><code>LayerRule</code></a> to apply a rule to the <code>n</code>-th layer of a model</li><li><a href="#ExplainableAI.GlobalRule"><code>GlobalRule</code></a> to apply a rule to all layers</li><li><a href="#ExplainableAI.RangeRule"><code>RangeRule</code></a> to apply a rule to a positional range of layers</li><li><a href="#ExplainableAI.FirstLayerRule"><code>FirstLayerRule</code></a> to apply a rule to the first layer</li><li><a href="#ExplainableAI.LastLayerRule"><code>LastLayerRule</code></a> to apply a rule to the last layer</li></ul><p>To apply a set of rules to layers based on their type, use:</p><ul><li><a href="#ExplainableAI.GlobalTypeRule"><code>GlobalTypeRule</code></a> to apply a dictionary that maps layer types to LRP-rules</li><li><a href="#ExplainableAI.RangeTypeRule"><code>RangeTypeRule</code></a> for a <code>TypeRule</code> on generalized ranges</li><li><a href="#ExplainableAI.FirstLayerTypeRule"><code>FirstLayerTypeRule</code></a> for a <code>TypeRule</code> on the first layer of a model</li><li><a href="#ExplainableAI.LastLayerTypeRule"><code>LastLayerTypeRule</code></a> for a <code>TypeRule</code> on the last layer</li><li><a href="#ExplainableAI.FirstNTypeRule"><code>FirstNTypeRule</code></a> for a <code>TypeRule</code> on the first <code>n</code> layers</li><li><a href="#ExplainableAI.LastNTypeRule"><code>LastNTypeRule</code></a> for a <code>TypeRule</code> on the last <code>n</code> layers</li></ul><p><strong>Example</strong></p><p>Using a flattened VGG11 model:</p><pre><code class="language-julia-repl hljs">julia&gt; composite = Composite(
           GlobalTypeRule(
               ConvLayer =&gt; AlphaBetaRule(),
               Dense =&gt; EpsilonRule(),
               PoolingLayer =&gt; EpsilonRule(),
               DropoutLayer =&gt; PassRule(),
               ReshapingLayer =&gt; PassRule(),
           ),
           FirstNTypeRule(7, Conv =&gt; FlatRule()),
       );

julia&gt; analyzer = LRP(model, composite);

julia&gt; analyzer.rules
19-element Vector{AbstractLRPRule}:
 FlatRule()
 EpsilonRule{Float32}(1.0f-6)
 FlatRule()
 EpsilonRule{Float32}(1.0f-6)
 FlatRule()
 FlatRule()
 EpsilonRule{Float32}(1.0f-6)
 AlphaBetaRule{Float32}(2.0f0, 1.0f0)
 AlphaBetaRule{Float32}(2.0f0, 1.0f0)
 EpsilonRule{Float32}(1.0f-6)
 AlphaBetaRule{Float32}(2.0f0, 1.0f0)
 AlphaBetaRule{Float32}(2.0f0, 1.0f0)
 EpsilonRule{Float32}(1.0f-6)
 PassRule()
 EpsilonRule{Float32}(1.0f-6)
 PassRule()
 EpsilonRule{Float32}(1.0f-6)
 PassRule()
 EpsilonRule{Float32}(1.0f-6)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L212-L271">source</a></section></article><h3 id="composite_primitive_api"><a class="docs-heading-anchor" href="#composite_primitive_api">Composite primitives</a><a id="composite_primitive_api-1"></a><a class="docs-heading-anchor-permalink" href="#composite_primitive_api" title="Permalink"></a></h3><p>Composite primitives that apply a single rule:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LayerRule" href="#ExplainableAI.LayerRule"><code>ExplainableAI.LayerRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LayerRule(n, rule)</code></pre><p>Composite primitive that applies LRP-rule <code>rule</code> to the <code>n</code>-th layer in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L27-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.GlobalRule" href="#ExplainableAI.GlobalRule"><code>ExplainableAI.GlobalRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalRule(rule)</code></pre><p>Composite primitive that applies LRP-rule <code>rule</code> to all layers in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L40-L46">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.RangeRule" href="#ExplainableAI.RangeRule"><code>ExplainableAI.RangeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RangeRule(range, rule)</code></pre><p>Composite primitive that applies LRP-rule <code>rule</code> to the specified positional <code>range</code> of layers in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L52-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.FirstLayerRule" href="#ExplainableAI.FirstLayerRule"><code>ExplainableAI.FirstLayerRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstLayerRule(rule)</code></pre><p>Composite primitive that applies LRP-rule <code>rule</code> to the first layer in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L70-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LastLayerRule" href="#ExplainableAI.LastLayerRule"><code>ExplainableAI.LastLayerRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LastLayerRule(rule)</code></pre><p>Composite primitive that applies LRP-rule <code>rule</code> to the last layer in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L82-L88">source</a></section></article><p>Composite primitives that apply a set of rules to multiple layers:</p><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.GlobalTypeRule" href="#ExplainableAI.GlobalTypeRule"><code>ExplainableAI.GlobalTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalTypeRule(map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L100-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.RangeTypeRule" href="#ExplainableAI.RangeTypeRule"><code>ExplainableAI.RangeTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RangeTypeRule(range, map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code> within the specified <code>range</code> of layers in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L115-L122">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.FirstLayerTypeRule" href="#ExplainableAI.FirstLayerTypeRule"><code>ExplainableAI.FirstLayerTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstLayerTypeRule(map)</code></pre><p>Composite primitive that maps the type of the first layer of the model to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L161-L168">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LastLayerTypeRule" href="#ExplainableAI.LastLayerTypeRule"><code>ExplainableAI.LastLayerTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LastLayerTypeRule(map)</code></pre><p>Composite primitive that maps the type of the last layer of the model to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L174-L181">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.FirstNTypeRule" href="#ExplainableAI.FirstNTypeRule"><code>ExplainableAI.FirstNTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstNTypeRule(n, map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code> within the first <code>n</code> layers in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L130-L137">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.LastNTypeRule" href="#ExplainableAI.LastNTypeRule"><code>ExplainableAI.LastNTypeRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LastNTypeRule(n, map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code> within the last <code>n</code> layers in the model.</p><p>See <a href="#ExplainableAI.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite.jl#L144-L151">source</a></section></article><h3 id="default_composite_api"><a class="docs-heading-anchor" href="#default_composite_api">Default composites</a><a id="default_composite_api-1"></a><a class="docs-heading-anchor-permalink" href="#default_composite_api" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonGammaBox" href="#ExplainableAI.EpsilonGammaBox"><code>ExplainableAI.EpsilonGammaBox</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonGammaBox(low, high; [epsilon=1.0f-6, gamma=0.25f0])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonGammaBox(-3.0f0, 3.0f0)
Composite(
  GlobalTypeRule(     # on all layers
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.GammaRule{Float32}(0.25f0),
    Flux.Dense =&gt; ExplainableAI.EpsilonRule{Float32}(1.0f-6),
    Union{typeof(Flux.dropout), Flux.AlphaDropout, Flux.Dropout} =&gt; ExplainableAI.PassRule(),
    Union{typeof(Flux.flatten), typeof(MLUtils.flatten)} =&gt; ExplainableAI.PassRule(),
  ),
  FirstLayerTypeRule( # on first layer
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.ZBoxRule{Float32}(-3.0f0, 3.0f0),
  ),
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite_presets.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonPlus" href="#ExplainableAI.EpsilonPlus"><code>ExplainableAI.EpsilonPlus</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonPlus(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonPlus()
Composite(
  GlobalTypeRule(     # on all layers
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.ZPlusRule(),
    Flux.Dense =&gt; ExplainableAI.EpsilonRule{Float32}(1.0f-6),
    Union{typeof(Flux.dropout), Flux.AlphaDropout, Flux.Dropout} =&gt; ExplainableAI.PassRule(),
    Union{typeof(Flux.flatten), typeof(MLUtils.flatten)} =&gt; ExplainableAI.PassRule(),
  ),
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite_presets.jl#L22-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonAlpha2Beta1" href="#ExplainableAI.EpsilonAlpha2Beta1"><code>ExplainableAI.EpsilonAlpha2Beta1</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonAlpha2Beta1(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonAlpha2Beta1()
Composite(
  GlobalTypeRule(     # on all layers
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.Dense =&gt; ExplainableAI.EpsilonRule{Float32}(1.0f-6),
    Union{typeof(Flux.dropout), Flux.AlphaDropout, Flux.Dropout} =&gt; ExplainableAI.PassRule(),
    Union{typeof(Flux.flatten), typeof(MLUtils.flatten)} =&gt; ExplainableAI.PassRule(),
  ),
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite_presets.jl#L42-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonPlusFlat" href="#ExplainableAI.EpsilonPlusFlat"><code>ExplainableAI.EpsilonPlusFlat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonPlusFlat(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonPlusFlat()
Composite(
  GlobalTypeRule(     # on all layers
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.ZPlusRule(),
    Flux.Dense =&gt; ExplainableAI.EpsilonRule{Float32}(1.0f-6),
    Union{typeof(Flux.dropout), Flux.AlphaDropout, Flux.Dropout} =&gt; ExplainableAI.PassRule(),
    Union{typeof(Flux.flatten), typeof(MLUtils.flatten)} =&gt; ExplainableAI.PassRule(),
  ),
  FirstLayerTypeRule( # on first layer
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.FlatRule(),
    Flux.Dense =&gt; ExplainableAI.FlatRule(),
  ),
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite_presets.jl#L62-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.EpsilonAlpha2Beta1Flat" href="#ExplainableAI.EpsilonAlpha2Beta1Flat"><code>ExplainableAI.EpsilonAlpha2Beta1Flat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonAlpha2Beta1Flat(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonAlpha2Beta1Flat()
Composite(
  GlobalTypeRule(     # on all layers
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.Dense =&gt; ExplainableAI.EpsilonRule{Float32}(1.0f-6),
    Union{typeof(Flux.dropout), Flux.AlphaDropout, Flux.Dropout} =&gt; ExplainableAI.PassRule(),
    Union{typeof(Flux.flatten), typeof(MLUtils.flatten)} =&gt; ExplainableAI.PassRule(),
  ),
  FirstLayerTypeRule( # on first layer
    Union{Flux.Conv, Flux.ConvTranspose, Flux.CrossCor} =&gt; ExplainableAI.FlatRule(),
    Flux.Dense =&gt; ExplainableAI.FlatRule(),
  ),
)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/composite_presets.jl#L83-L91">source</a></section></article><h1 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.strip_softmax" href="#ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">strip_softmax(model)</code></pre><p>Remove softmax activation on model output if it exists.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/flux_utils.jl#L55-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.flatten_model" href="#ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">flatten_model(c)</code></pre><p>Flatten a Flux chain containing Flux chains.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/flux_utils.jl#L20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ExplainableAI.canonize" href="#ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">canonize(model)</code></pre><p>Canonize model by flattening it and fusing BatchNorm layers into preceding Dense and Conv layers with linear activation functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/adrhill/ExplainableAI.jl/blob/bf4c581f9c8f3bdce3e19c24fbd94a3c3a06e63e/src/lrp/canonize.jl#L37-L42">source</a></section></article><h1 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h1><ul><li><a href="#ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a></li><li><a href="#ExplainableAI.Composite"><code>ExplainableAI.Composite</code></a></li><li><a href="#ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a></li><li><a href="#ExplainableAI.Explanation"><code>ExplainableAI.Explanation</code></a></li><li><a href="#ExplainableAI.FirstLayerRule"><code>ExplainableAI.FirstLayerRule</code></a></li><li><a href="#ExplainableAI.FirstLayerTypeRule"><code>ExplainableAI.FirstLayerTypeRule</code></a></li><li><a href="#ExplainableAI.FirstNTypeRule"><code>ExplainableAI.FirstNTypeRule</code></a></li><li><a href="#ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a></li><li><a href="#ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a></li><li><a href="#ExplainableAI.GlobalRule"><code>ExplainableAI.GlobalRule</code></a></li><li><a href="#ExplainableAI.GlobalTypeRule"><code>ExplainableAI.GlobalTypeRule</code></a></li><li><a href="#ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a></li><li><a href="#ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a></li><li><a href="#ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a></li><li><a href="#ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a></li><li><a href="#ExplainableAI.LastLayerRule"><code>ExplainableAI.LastLayerRule</code></a></li><li><a href="#ExplainableAI.LastLayerTypeRule"><code>ExplainableAI.LastLayerTypeRule</code></a></li><li><a href="#ExplainableAI.LastNTypeRule"><code>ExplainableAI.LastNTypeRule</code></a></li><li><a href="#ExplainableAI.LayerRule"><code>ExplainableAI.LayerRule</code></a></li><li><a href="#ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a></li><li><a href="#ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a></li><li><a href="#ExplainableAI.RangeRule"><code>ExplainableAI.RangeRule</code></a></li><li><a href="#ExplainableAI.RangeTypeRule"><code>ExplainableAI.RangeTypeRule</code></a></li><li><a href="#ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a></li><li><a href="#ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a></li><li><a href="#ExplainableAI.ZPlusRule"><code>ExplainableAI.ZPlusRule</code></a></li><li><a href="#ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a></li><li><a href="#ExplainableAI.EpsilonAlpha2Beta1"><code>ExplainableAI.EpsilonAlpha2Beta1</code></a></li><li><a href="#ExplainableAI.EpsilonAlpha2Beta1Flat"><code>ExplainableAI.EpsilonAlpha2Beta1Flat</code></a></li><li><a href="#ExplainableAI.EpsilonGammaBox"><code>ExplainableAI.EpsilonGammaBox</code></a></li><li><a href="#ExplainableAI.EpsilonPlus"><code>ExplainableAI.EpsilonPlus</code></a></li><li><a href="#ExplainableAI.EpsilonPlusFlat"><code>ExplainableAI.EpsilonPlusFlat</code></a></li><li><a href="#ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a></li><li><a href="#ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a></li><li><a href="#ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a></li><li><a href="#ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a></li><li><a href="#ExplainableAI.check_compat"><code>ExplainableAI.check_compat</code></a></li><li><a href="#ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a></li><li><a href="#ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a></li><li><a href="#ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a></li><li><a href="#ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a></li><li><a href="#ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a></li><li><a href="#ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a></li><li><a href="#ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../generated/advanced_lrp/">« Advanced LRP</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Friday 19 August 2022 15:24">Friday 19 August 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
